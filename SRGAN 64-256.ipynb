{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "        data = []\n",
    "        small = []\n",
    "        paths = []\n",
    "        #get all files in this folder\n",
    "        for r, d, f in os.walk(r\"D:\\Downloads\\selfie2anime\\trainB\"):\n",
    "            for file in f:\n",
    "                if '.jpg' in file:\n",
    "                    paths.append(os.path.join(r, file))\n",
    "        #for each file add normal resolution and low resolution to arrays\n",
    "        for path in paths:\n",
    "            img = Image.open(path)\n",
    "            x = np.array(img.resize((64,64)))\n",
    "            y = np.array(img)\n",
    "            #uncomment to remove alpha channel for PNGs\n",
    "            #x = x[...,:3]\n",
    "            data.append(y)\n",
    "            small.append(x)\n",
    "            \n",
    "        #reshaping data to be four dimension required for input to neural network\n",
    "        y_train = np.array(data)\n",
    "        y_train = y_train.reshape(len(data),256,256,3)\n",
    "        x_train = np.array(small)\n",
    "        x_train = x_train.reshape(len(small),64,64,3)\n",
    "        return y_train, x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRGAN():\n",
    "    def __init__(self):\n",
    "        \n",
    "        # Shape of high resolution output image\n",
    "        self.img_rows = 256\n",
    "        self.img_cols = 256\n",
    "        self.channels = 3\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        \n",
    "        # Shape of low resolution input image\n",
    "        self.latent_dim = (64,64,3)\n",
    "\n",
    "        #optimizer (learning rate and beta values)\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "        generator = self.generator\n",
    "\n",
    "        # The generator takes noise as input and generates imgs\n",
    "        z = Input(shape=self.latent_dim)\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(120, input_shape=self.latent_dim, kernel_size=(3,3), padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Conv2D(120, kernel_size=(3,3), padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(120, kernel_size=(2,2), padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Conv2D(120, kernel_size=(4,4), padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(120, kernel_size=(3,3), padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Conv2D(120, kernel_size=(3,3), padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Conv2D(3, kernel_size=(2,2), padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=self.latent_dim)\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "    \n",
    "\n",
    "    def train(self, epochs, batch_size=128, save_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        Y_train, X_train = load_data()\n",
    "\n",
    "        # Rescale to be between 0 & 1\n",
    "        X_train = X_train / 255\n",
    "        Y_train = Y_train / 255\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "        \n",
    "        # Placeholder for loss function values\n",
    "        g_loss_epochs = np.zeros((epochs, 1))\n",
    "        d_loss_epochs = np.zeros((epochs, 1))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random batch of images\n",
    "            idx = np.random.randint(0, Y_train.shape[0], batch_size)\n",
    "            imgs = Y_train[idx]\n",
    "\n",
    "            # Generate super resolution images from the random batch of images\n",
    "            gen_imgs = self.generator.predict(X_train[idx])\n",
    "\n",
    "            # Train the discriminator (real classified as ones and generated as zeros)\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            # Train the generator (wants discriminator to mistake images as real)\n",
    "            g_loss = self.combined.train_on_batch(X_train[idx], valid)\n",
    "            \n",
    "            #save loss history\n",
    "            g_loss_epochs[epoch] = g_loss\n",
    "            d_loss_epochs[epoch] = d_loss[0]\n",
    "\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % save_interval == 0:\n",
    "                self.save_imgs(epoch, X_train, idx)\n",
    "            \n",
    "        return g_loss_epochs, d_loss_epochs\n",
    "\n",
    "    def save_imgs(self, epoch, X_train, idx):\n",
    "        r, c = 3, 3\n",
    "        # Select 9 random images\n",
    "        index = np.random.randint(0, X_train.shape[0], 100)\n",
    "        images = X_train[idx]\n",
    "        # Super resolution the images\n",
    "        gen_imgs = self.generator.predict(images)\n",
    "        gen_imgs = np.array(gen_imgs) * 255\n",
    "        gen_imgs = gen_imgs.astype(int)\n",
    "        # Plot each image\n",
    "        fig=plt.figure(figsize=(20, 20))\n",
    "        for i in range(1, c*r+1):\n",
    "            img = gen_imgs[i-1]\n",
    "            fig.add_subplot(r, c, i)\n",
    "            plt.imshow(img)\n",
    "        fig.savefig(r\"C:\\Users\\Vee\\Desktop\\python\\GAN\\epoch_%d.png\" % epoch)\n",
    "        plt.close()\n",
    "        # save model to .h5 file\n",
    "        self.generator.save(\"generator.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 131072)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 131073    \n",
      "=================================================================\n",
      "Total params: 225,089\n",
      "Trainable params: 224,705\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\Vee\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 64, 64, 120)       3360      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 64, 64, 120)       480       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 64, 64, 120)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 64, 64, 120)       129720    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 64, 64, 120)       480       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 64, 64, 120)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 128, 128, 120)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 128, 128, 120)     57720     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 128, 128, 120)     480       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 128, 128, 120)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 128, 128, 120)     230520    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 128, 128, 120)     480       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 128, 128, 120)     0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 256, 256, 120)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 256, 256, 120)     129720    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 256, 256, 120)     480       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 256, 256, 120)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 256, 256, 120)     129720    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 256, 256, 120)     480       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 256, 256, 120)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 256, 256, 3)       1443      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 256, 256, 3)       0         \n",
      "=================================================================\n",
      "Total params: 685,083\n",
      "Trainable params: 683,643\n",
      "Non-trainable params: 1,440\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan = SRGAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Vee\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vee\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n",
      "C:\\Users\\Vee\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 3.784798, acc.: 15.00%] [G loss: 0.073473]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "C:\\Users\\Vee\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [D loss: 1.165950, acc.: 50.00%] [G loss: 3.827034]\n",
      "2 [D loss: 2.350181, acc.: 40.00%] [G loss: 1.334147]\n",
      "3 [D loss: 1.926417, acc.: 5.00%] [G loss: 0.867204]\n",
      "4 [D loss: 1.202445, acc.: 30.00%] [G loss: 0.693736]\n",
      "5 [D loss: 1.226032, acc.: 35.00%] [G loss: 0.102739]\n",
      "6 [D loss: 1.362086, acc.: 30.00%] [G loss: 0.374709]\n",
      "7 [D loss: 0.937363, acc.: 60.00%] [G loss: 0.149160]\n",
      "8 [D loss: 0.657709, acc.: 75.00%] [G loss: 0.145050]\n",
      "9 [D loss: 0.179395, acc.: 95.00%] [G loss: 0.207185]\n",
      "10 [D loss: 0.200716, acc.: 90.00%] [G loss: 0.230032]\n",
      "11 [D loss: 0.327591, acc.: 85.00%] [G loss: 0.672062]\n",
      "12 [D loss: 0.376309, acc.: 80.00%] [G loss: 1.212704]\n",
      "13 [D loss: 1.469352, acc.: 20.00%] [G loss: 1.205878]\n",
      "14 [D loss: 0.888557, acc.: 60.00%] [G loss: 2.128604]\n",
      "15 [D loss: 1.025703, acc.: 30.00%] [G loss: 1.888548]\n",
      "16 [D loss: 0.838889, acc.: 50.00%] [G loss: 5.226865]\n",
      "17 [D loss: 2.169756, acc.: 5.00%] [G loss: 2.930492]\n",
      "18 [D loss: 2.288221, acc.: 10.00%] [G loss: 2.844561]\n",
      "19 [D loss: 1.572456, acc.: 30.00%] [G loss: 1.330529]\n",
      "20 [D loss: 2.249054, acc.: 10.00%] [G loss: 1.530382]\n",
      "21 [D loss: 0.812631, acc.: 55.00%] [G loss: 2.874669]\n",
      "22 [D loss: 1.348683, acc.: 35.00%] [G loss: 3.505459]\n",
      "23 [D loss: 1.781223, acc.: 25.00%] [G loss: 5.710581]\n",
      "24 [D loss: 0.742752, acc.: 65.00%] [G loss: 3.557533]\n",
      "25 [D loss: 1.866454, acc.: 30.00%] [G loss: 5.047308]\n",
      "26 [D loss: 1.264632, acc.: 30.00%] [G loss: 4.238694]\n",
      "27 [D loss: 1.833061, acc.: 25.00%] [G loss: 5.307199]\n",
      "28 [D loss: 1.437050, acc.: 25.00%] [G loss: 5.242020]\n",
      "29 [D loss: 2.030107, acc.: 25.00%] [G loss: 1.061947]\n",
      "30 [D loss: 0.927493, acc.: 60.00%] [G loss: 3.013086]\n",
      "31 [D loss: 1.742402, acc.: 25.00%] [G loss: 1.677415]\n",
      "32 [D loss: 0.748874, acc.: 65.00%] [G loss: 1.430845]\n",
      "33 [D loss: 0.873329, acc.: 55.00%] [G loss: 0.367052]\n",
      "34 [D loss: 1.211215, acc.: 50.00%] [G loss: 2.851836]\n",
      "35 [D loss: 2.787595, acc.: 10.00%] [G loss: 2.504761]\n",
      "36 [D loss: 1.613968, acc.: 40.00%] [G loss: 1.884344]\n",
      "37 [D loss: 1.326623, acc.: 40.00%] [G loss: 2.064188]\n",
      "38 [D loss: 1.409052, acc.: 35.00%] [G loss: 0.493721]\n",
      "39 [D loss: 1.133535, acc.: 40.00%] [G loss: 1.515703]\n",
      "40 [D loss: 1.088123, acc.: 35.00%] [G loss: 1.676132]\n",
      "41 [D loss: 1.208690, acc.: 50.00%] [G loss: 1.246693]\n",
      "42 [D loss: 2.625769, acc.: 5.00%] [G loss: 1.949630]\n",
      "43 [D loss: 2.088922, acc.: 10.00%] [G loss: 2.027105]\n",
      "44 [D loss: 1.206692, acc.: 30.00%] [G loss: 4.170547]\n",
      "45 [D loss: 1.941755, acc.: 20.00%] [G loss: 1.755384]\n",
      "46 [D loss: 2.395439, acc.: 25.00%] [G loss: 2.693541]\n",
      "47 [D loss: 2.864506, acc.: 10.00%] [G loss: 1.310100]\n",
      "48 [D loss: 2.216718, acc.: 5.00%] [G loss: 0.920719]\n",
      "49 [D loss: 1.611745, acc.: 30.00%] [G loss: 1.644985]\n",
      "50 [D loss: 2.581692, acc.: 20.00%] [G loss: 1.207749]\n",
      "51 [D loss: 1.263202, acc.: 30.00%] [G loss: 2.125545]\n",
      "52 [D loss: 1.822968, acc.: 15.00%] [G loss: 1.736264]\n",
      "53 [D loss: 2.719934, acc.: 5.00%] [G loss: 1.442719]\n",
      "54 [D loss: 1.053180, acc.: 55.00%] [G loss: 0.960237]\n",
      "55 [D loss: 1.789754, acc.: 30.00%] [G loss: 3.639657]\n",
      "56 [D loss: 2.526416, acc.: 20.00%] [G loss: 2.777979]\n",
      "57 [D loss: 1.596057, acc.: 35.00%] [G loss: 2.695945]\n",
      "58 [D loss: 1.962133, acc.: 20.00%] [G loss: 1.940410]\n",
      "59 [D loss: 1.755638, acc.: 20.00%] [G loss: 1.366932]\n",
      "60 [D loss: 1.735406, acc.: 20.00%] [G loss: 1.812315]\n",
      "61 [D loss: 1.571637, acc.: 15.00%] [G loss: 1.559922]\n",
      "62 [D loss: 1.947968, acc.: 15.00%] [G loss: 1.556406]\n",
      "63 [D loss: 2.387835, acc.: 10.00%] [G loss: 1.154690]\n",
      "64 [D loss: 2.108333, acc.: 5.00%] [G loss: 1.457164]\n",
      "65 [D loss: 2.226285, acc.: 10.00%] [G loss: 2.541033]\n",
      "66 [D loss: 2.310779, acc.: 20.00%] [G loss: 0.803967]\n",
      "67 [D loss: 1.665219, acc.: 30.00%] [G loss: 2.360101]\n",
      "68 [D loss: 2.015441, acc.: 10.00%] [G loss: 1.676305]\n",
      "69 [D loss: 3.180162, acc.: 0.00%] [G loss: 1.393281]\n",
      "70 [D loss: 1.538975, acc.: 35.00%] [G loss: 2.134665]\n",
      "71 [D loss: 1.728636, acc.: 25.00%] [G loss: 1.810188]\n",
      "72 [D loss: 2.094070, acc.: 15.00%] [G loss: 1.575424]\n",
      "73 [D loss: 2.328660, acc.: 0.00%] [G loss: 1.623880]\n",
      "74 [D loss: 1.630540, acc.: 25.00%] [G loss: 2.414348]\n",
      "75 [D loss: 2.464497, acc.: 5.00%] [G loss: 1.849442]\n",
      "76 [D loss: 1.436230, acc.: 35.00%] [G loss: 1.857808]\n",
      "77 [D loss: 2.041096, acc.: 15.00%] [G loss: 1.996333]\n",
      "78 [D loss: 2.441918, acc.: 0.00%] [G loss: 2.310025]\n",
      "79 [D loss: 1.541501, acc.: 30.00%] [G loss: 1.959621]\n",
      "80 [D loss: 1.499001, acc.: 30.00%] [G loss: 2.350809]\n",
      "81 [D loss: 1.022111, acc.: 35.00%] [G loss: 2.128580]\n",
      "82 [D loss: 1.436688, acc.: 40.00%] [G loss: 1.322187]\n",
      "83 [D loss: 1.800039, acc.: 10.00%] [G loss: 2.603812]\n",
      "84 [D loss: 1.162621, acc.: 35.00%] [G loss: 1.796437]\n",
      "85 [D loss: 2.022932, acc.: 0.00%] [G loss: 1.611559]\n",
      "86 [D loss: 1.461596, acc.: 20.00%] [G loss: 1.925386]\n",
      "87 [D loss: 1.335988, acc.: 40.00%] [G loss: 2.385515]\n",
      "88 [D loss: 2.620021, acc.: 5.00%] [G loss: 2.545865]\n",
      "89 [D loss: 1.008998, acc.: 45.00%] [G loss: 2.574488]\n",
      "90 [D loss: 1.352399, acc.: 20.00%] [G loss: 0.981660]\n",
      "91 [D loss: 1.308701, acc.: 35.00%] [G loss: 1.904554]\n",
      "92 [D loss: 1.541029, acc.: 25.00%] [G loss: 2.297761]\n",
      "93 [D loss: 2.240885, acc.: 10.00%] [G loss: 2.204287]\n",
      "94 [D loss: 1.516753, acc.: 30.00%] [G loss: 2.172012]\n",
      "95 [D loss: 1.615147, acc.: 20.00%] [G loss: 2.343597]\n",
      "96 [D loss: 1.638024, acc.: 5.00%] [G loss: 1.737757]\n",
      "97 [D loss: 1.290802, acc.: 20.00%] [G loss: 2.005435]\n",
      "98 [D loss: 1.602345, acc.: 10.00%] [G loss: 2.261387]\n",
      "99 [D loss: 2.006387, acc.: 5.00%] [G loss: 1.742685]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 [D loss: 1.732024, acc.: 25.00%] [G loss: 2.263324]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 [D loss: 1.296933, acc.: 25.00%] [G loss: 2.885233]\n",
      "102 [D loss: 1.845468, acc.: 15.00%] [G loss: 2.714397]\n",
      "103 [D loss: 1.973016, acc.: 5.00%] [G loss: 1.376150]\n",
      "104 [D loss: 1.164681, acc.: 35.00%] [G loss: 2.314703]\n",
      "105 [D loss: 1.580196, acc.: 20.00%] [G loss: 2.226704]\n",
      "106 [D loss: 2.119019, acc.: 15.00%] [G loss: 1.756317]\n",
      "107 [D loss: 2.294330, acc.: 10.00%] [G loss: 1.921013]\n",
      "108 [D loss: 1.514596, acc.: 30.00%] [G loss: 2.557069]\n",
      "109 [D loss: 1.741744, acc.: 15.00%] [G loss: 1.159971]\n",
      "110 [D loss: 1.393289, acc.: 25.00%] [G loss: 1.606078]\n",
      "111 [D loss: 1.340017, acc.: 45.00%] [G loss: 2.364055]\n",
      "112 [D loss: 2.084590, acc.: 15.00%] [G loss: 2.727737]\n",
      "113 [D loss: 1.789478, acc.: 35.00%] [G loss: 1.597267]\n",
      "114 [D loss: 1.326199, acc.: 30.00%] [G loss: 2.144235]\n",
      "115 [D loss: 1.466937, acc.: 50.00%] [G loss: 1.141126]\n",
      "116 [D loss: 2.147977, acc.: 20.00%] [G loss: 1.180187]\n",
      "117 [D loss: 1.097584, acc.: 45.00%] [G loss: 2.869786]\n",
      "118 [D loss: 2.687496, acc.: 15.00%] [G loss: 2.542782]\n",
      "119 [D loss: 2.149158, acc.: 15.00%] [G loss: 1.622068]\n",
      "120 [D loss: 1.456587, acc.: 20.00%] [G loss: 3.064853]\n",
      "121 [D loss: 1.625959, acc.: 30.00%] [G loss: 1.231474]\n",
      "122 [D loss: 1.592913, acc.: 30.00%] [G loss: 1.587163]\n",
      "123 [D loss: 1.283369, acc.: 35.00%] [G loss: 1.874271]\n",
      "124 [D loss: 1.523487, acc.: 15.00%] [G loss: 2.215274]\n",
      "125 [D loss: 1.076375, acc.: 40.00%] [G loss: 1.836313]\n",
      "126 [D loss: 1.213977, acc.: 35.00%] [G loss: 1.165978]\n",
      "127 [D loss: 1.229433, acc.: 35.00%] [G loss: 2.787180]\n",
      "128 [D loss: 1.542610, acc.: 30.00%] [G loss: 2.586766]\n",
      "129 [D loss: 1.584876, acc.: 15.00%] [G loss: 1.930861]\n",
      "130 [D loss: 1.603848, acc.: 25.00%] [G loss: 3.135430]\n",
      "131 [D loss: 1.783707, acc.: 10.00%] [G loss: 2.291255]\n",
      "132 [D loss: 1.743082, acc.: 30.00%] [G loss: 1.786345]\n",
      "133 [D loss: 1.915955, acc.: 15.00%] [G loss: 1.814825]\n",
      "134 [D loss: 1.277448, acc.: 20.00%] [G loss: 1.357836]\n",
      "135 [D loss: 1.820190, acc.: 10.00%] [G loss: 2.094421]\n",
      "136 [D loss: 1.706238, acc.: 20.00%] [G loss: 1.597467]\n",
      "137 [D loss: 1.338555, acc.: 45.00%] [G loss: 2.945359]\n",
      "138 [D loss: 1.821176, acc.: 30.00%] [G loss: 1.763890]\n",
      "139 [D loss: 2.374948, acc.: 0.00%] [G loss: 1.624668]\n",
      "140 [D loss: 1.205711, acc.: 45.00%] [G loss: 2.654176]\n",
      "141 [D loss: 2.138684, acc.: 5.00%] [G loss: 2.432221]\n",
      "142 [D loss: 1.141434, acc.: 45.00%] [G loss: 1.809425]\n",
      "143 [D loss: 1.086992, acc.: 40.00%] [G loss: 2.465492]\n",
      "144 [D loss: 1.537943, acc.: 20.00%] [G loss: 1.307430]\n",
      "145 [D loss: 1.463730, acc.: 25.00%] [G loss: 2.058224]\n",
      "146 [D loss: 1.455186, acc.: 25.00%] [G loss: 1.289406]\n",
      "147 [D loss: 1.581573, acc.: 20.00%] [G loss: 2.400763]\n",
      "148 [D loss: 1.380414, acc.: 20.00%] [G loss: 2.199833]\n",
      "149 [D loss: 1.470467, acc.: 35.00%] [G loss: 2.145652]\n",
      "150 [D loss: 1.459797, acc.: 20.00%] [G loss: 2.375413]\n",
      "151 [D loss: 1.082997, acc.: 30.00%] [G loss: 2.071901]\n",
      "152 [D loss: 2.300977, acc.: 10.00%] [G loss: 1.251326]\n",
      "153 [D loss: 0.992167, acc.: 40.00%] [G loss: 3.198499]\n",
      "154 [D loss: 1.680026, acc.: 25.00%] [G loss: 2.792893]\n",
      "155 [D loss: 2.211758, acc.: 5.00%] [G loss: 1.109694]\n",
      "156 [D loss: 0.697531, acc.: 65.00%] [G loss: 3.406215]\n",
      "157 [D loss: 1.751437, acc.: 10.00%] [G loss: 1.501989]\n",
      "158 [D loss: 1.649788, acc.: 30.00%] [G loss: 2.412097]\n",
      "159 [D loss: 1.782841, acc.: 10.00%] [G loss: 2.897157]\n",
      "160 [D loss: 1.576166, acc.: 30.00%] [G loss: 1.538598]\n",
      "161 [D loss: 1.369323, acc.: 25.00%] [G loss: 1.997038]\n",
      "162 [D loss: 1.046050, acc.: 35.00%] [G loss: 2.118050]\n",
      "163 [D loss: 1.295898, acc.: 30.00%] [G loss: 2.687932]\n",
      "164 [D loss: 1.922302, acc.: 20.00%] [G loss: 2.162542]\n",
      "165 [D loss: 1.421667, acc.: 25.00%] [G loss: 1.804415]\n",
      "166 [D loss: 1.308057, acc.: 35.00%] [G loss: 2.508744]\n",
      "167 [D loss: 1.166053, acc.: 30.00%] [G loss: 2.287477]\n",
      "168 [D loss: 0.818160, acc.: 45.00%] [G loss: 1.032382]\n",
      "169 [D loss: 0.770200, acc.: 60.00%] [G loss: 2.512605]\n",
      "170 [D loss: 1.618600, acc.: 10.00%] [G loss: 1.989683]\n",
      "171 [D loss: 1.375518, acc.: 30.00%] [G loss: 1.808534]\n",
      "172 [D loss: 1.181222, acc.: 40.00%] [G loss: 2.124081]\n",
      "173 [D loss: 0.946978, acc.: 35.00%] [G loss: 3.205744]\n",
      "174 [D loss: 1.257643, acc.: 40.00%] [G loss: 1.861863]\n",
      "175 [D loss: 1.984161, acc.: 10.00%] [G loss: 2.593247]\n",
      "176 [D loss: 0.855582, acc.: 70.00%] [G loss: 2.071229]\n",
      "177 [D loss: 0.794006, acc.: 60.00%] [G loss: 2.420659]\n",
      "178 [D loss: 0.736073, acc.: 55.00%] [G loss: 2.266177]\n",
      "179 [D loss: 1.376099, acc.: 20.00%] [G loss: 1.081208]\n",
      "180 [D loss: 0.554011, acc.: 70.00%] [G loss: 3.253583]\n",
      "181 [D loss: 1.452390, acc.: 30.00%] [G loss: 1.137117]\n",
      "182 [D loss: 0.924796, acc.: 60.00%] [G loss: 2.644487]\n",
      "183 [D loss: 2.310011, acc.: 20.00%] [G loss: 2.343562]\n",
      "184 [D loss: 0.670357, acc.: 60.00%] [G loss: 2.599247]\n",
      "185 [D loss: 0.831494, acc.: 60.00%] [G loss: 1.131226]\n",
      "186 [D loss: 0.865941, acc.: 55.00%] [G loss: 3.398368]\n",
      "187 [D loss: 0.797377, acc.: 55.00%] [G loss: 3.252190]\n",
      "188 [D loss: 1.567602, acc.: 20.00%] [G loss: 2.032306]\n",
      "189 [D loss: 0.951269, acc.: 60.00%] [G loss: 3.205097]\n",
      "190 [D loss: 1.528383, acc.: 20.00%] [G loss: 0.806959]\n",
      "191 [D loss: 1.028395, acc.: 40.00%] [G loss: 3.469607]\n",
      "192 [D loss: 0.743972, acc.: 65.00%] [G loss: 3.406687]\n",
      "193 [D loss: 1.417897, acc.: 25.00%] [G loss: 1.895535]\n",
      "194 [D loss: 0.559680, acc.: 75.00%] [G loss: 3.421052]\n",
      "195 [D loss: 1.870915, acc.: 15.00%] [G loss: 3.390813]\n",
      "196 [D loss: 0.644625, acc.: 60.00%] [G loss: 2.945073]\n",
      "197 [D loss: 0.883987, acc.: 55.00%] [G loss: 2.601031]\n",
      "198 [D loss: 0.759603, acc.: 60.00%] [G loss: 2.488125]\n",
      "199 [D loss: 1.743786, acc.: 10.00%] [G loss: 2.416713]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 [D loss: 0.807619, acc.: 65.00%] [G loss: 1.984088]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201 [D loss: 0.992887, acc.: 50.00%] [G loss: 3.244300]\n",
      "202 [D loss: 0.913461, acc.: 35.00%] [G loss: 2.366419]\n",
      "203 [D loss: 0.751263, acc.: 70.00%] [G loss: 1.979431]\n",
      "204 [D loss: 0.407713, acc.: 85.00%] [G loss: 1.962058]\n",
      "205 [D loss: 0.578788, acc.: 75.00%] [G loss: 1.647636]\n",
      "206 [D loss: 0.649984, acc.: 70.00%] [G loss: 3.256628]\n",
      "207 [D loss: 0.824163, acc.: 65.00%] [G loss: 3.192018]\n",
      "208 [D loss: 1.208231, acc.: 50.00%] [G loss: 1.500039]\n",
      "209 [D loss: 0.212377, acc.: 95.00%] [G loss: 2.122628]\n",
      "210 [D loss: 0.304082, acc.: 90.00%] [G loss: 1.501197]\n",
      "211 [D loss: 1.174528, acc.: 35.00%] [G loss: 4.562957]\n",
      "212 [D loss: 0.701588, acc.: 65.00%] [G loss: 1.473654]\n",
      "213 [D loss: 0.717404, acc.: 50.00%] [G loss: 2.909315]\n",
      "214 [D loss: 0.466691, acc.: 70.00%] [G loss: 2.456168]\n",
      "215 [D loss: 0.366249, acc.: 85.00%] [G loss: 3.682759]\n",
      "216 [D loss: 0.864525, acc.: 55.00%] [G loss: 2.553951]\n",
      "217 [D loss: 0.201780, acc.: 100.00%] [G loss: 2.788318]\n",
      "218 [D loss: 0.339343, acc.: 80.00%] [G loss: 4.058806]\n",
      "219 [D loss: 0.165771, acc.: 100.00%] [G loss: 2.180327]\n",
      "220 [D loss: 0.667262, acc.: 60.00%] [G loss: 4.892105]\n",
      "221 [D loss: 0.489421, acc.: 75.00%] [G loss: 2.979096]\n",
      "222 [D loss: 0.350419, acc.: 90.00%] [G loss: 3.881403]\n",
      "223 [D loss: 0.226766, acc.: 95.00%] [G loss: 2.267171]\n",
      "224 [D loss: 0.420431, acc.: 75.00%] [G loss: 2.929725]\n",
      "225 [D loss: 0.228366, acc.: 95.00%] [G loss: 3.856742]\n",
      "226 [D loss: 1.015061, acc.: 40.00%] [G loss: 3.599693]\n",
      "227 [D loss: 0.175167, acc.: 90.00%] [G loss: 2.125435]\n",
      "228 [D loss: 0.256644, acc.: 95.00%] [G loss: 1.986858]\n",
      "229 [D loss: 0.175230, acc.: 100.00%] [G loss: 2.115418]\n",
      "230 [D loss: 1.112513, acc.: 45.00%] [G loss: 1.627925]\n",
      "231 [D loss: 0.178108, acc.: 95.00%] [G loss: 3.995217]\n",
      "232 [D loss: 1.604274, acc.: 10.00%] [G loss: 2.781112]\n",
      "233 [D loss: 0.129485, acc.: 100.00%] [G loss: 3.983288]\n",
      "234 [D loss: 1.835039, acc.: 35.00%] [G loss: 0.318166]\n",
      "235 [D loss: 0.412525, acc.: 75.00%] [G loss: 2.950114]\n",
      "236 [D loss: 0.241202, acc.: 85.00%] [G loss: 4.348138]\n",
      "237 [D loss: 0.561229, acc.: 70.00%] [G loss: 2.704335]\n",
      "238 [D loss: 1.261841, acc.: 35.00%] [G loss: 2.190758]\n",
      "239 [D loss: 0.181920, acc.: 95.00%] [G loss: 4.315518]\n",
      "240 [D loss: 0.706637, acc.: 70.00%] [G loss: 0.666967]\n",
      "241 [D loss: 0.759292, acc.: 65.00%] [G loss: 4.550980]\n",
      "242 [D loss: 1.383492, acc.: 45.00%] [G loss: 4.713312]\n",
      "243 [D loss: 1.102429, acc.: 55.00%] [G loss: 5.571751]\n",
      "244 [D loss: 1.250384, acc.: 40.00%] [G loss: 0.449939]\n",
      "245 [D loss: 1.522098, acc.: 55.00%] [G loss: 5.362641]\n",
      "246 [D loss: 1.253000, acc.: 55.00%] [G loss: 2.441217]\n",
      "247 [D loss: 0.399152, acc.: 85.00%] [G loss: 0.413156]\n",
      "248 [D loss: 0.167158, acc.: 90.00%] [G loss: 1.858728]\n",
      "249 [D loss: 0.454231, acc.: 85.00%] [G loss: 2.494235]\n",
      "250 [D loss: 0.392055, acc.: 80.00%] [G loss: 3.065308]\n",
      "251 [D loss: 0.249903, acc.: 95.00%] [G loss: 2.356652]\n",
      "252 [D loss: 0.279999, acc.: 75.00%] [G loss: 2.187570]\n",
      "253 [D loss: 0.761452, acc.: 60.00%] [G loss: 4.039025]\n",
      "254 [D loss: 1.591967, acc.: 20.00%] [G loss: 5.562857]\n",
      "255 [D loss: 3.458289, acc.: 50.00%] [G loss: 1.840556]\n",
      "256 [D loss: 0.342398, acc.: 85.00%] [G loss: 0.332961]\n",
      "257 [D loss: 0.065270, acc.: 100.00%] [G loss: 0.752855]\n",
      "258 [D loss: 2.717754, acc.: 50.00%] [G loss: 2.462370]\n",
      "259 [D loss: 0.908372, acc.: 65.00%] [G loss: 7.022261]\n",
      "260 [D loss: 0.784244, acc.: 70.00%] [G loss: 1.490470]\n",
      "261 [D loss: 1.091450, acc.: 60.00%] [G loss: 5.639500]\n",
      "262 [D loss: 0.733613, acc.: 65.00%] [G loss: 1.181762]\n",
      "263 [D loss: 0.232060, acc.: 90.00%] [G loss: 1.350847]\n",
      "264 [D loss: 0.038323, acc.: 100.00%] [G loss: 0.751545]\n",
      "265 [D loss: 0.124472, acc.: 95.00%] [G loss: 0.790240]\n",
      "266 [D loss: 0.981363, acc.: 60.00%] [G loss: 0.650814]\n",
      "267 [D loss: 0.168635, acc.: 95.00%] [G loss: 7.803843]\n",
      "268 [D loss: 2.052730, acc.: 50.00%] [G loss: 0.292589]\n",
      "269 [D loss: 1.679860, acc.: 60.00%] [G loss: 2.410629]\n",
      "270 [D loss: 0.418701, acc.: 80.00%] [G loss: 1.738436]\n",
      "271 [D loss: 2.653649, acc.: 15.00%] [G loss: 1.258388]\n",
      "272 [D loss: 1.738163, acc.: 45.00%] [G loss: 1.472012]\n",
      "273 [D loss: 1.077657, acc.: 35.00%] [G loss: 2.477195]\n",
      "274 [D loss: 1.461579, acc.: 45.00%] [G loss: 5.743040]\n",
      "275 [D loss: 2.876985, acc.: 20.00%] [G loss: 1.615416]\n",
      "276 [D loss: 2.882832, acc.: 10.00%] [G loss: 1.777378]\n",
      "277 [D loss: 1.179461, acc.: 50.00%] [G loss: 3.091388]\n",
      "278 [D loss: 2.880789, acc.: 5.00%] [G loss: 1.851127]\n",
      "279 [D loss: 1.471031, acc.: 30.00%] [G loss: 3.665107]\n",
      "280 [D loss: 1.677204, acc.: 30.00%] [G loss: 3.121255]\n",
      "281 [D loss: 1.739181, acc.: 40.00%] [G loss: 1.552117]\n",
      "282 [D loss: 0.942564, acc.: 45.00%] [G loss: 2.729968]\n",
      "283 [D loss: 1.540422, acc.: 55.00%] [G loss: 5.144598]\n",
      "284 [D loss: 2.017470, acc.: 35.00%] [G loss: 3.276032]\n",
      "285 [D loss: 2.837773, acc.: 0.00%] [G loss: 4.872443]\n",
      "286 [D loss: 1.440377, acc.: 45.00%] [G loss: 5.908579]\n",
      "287 [D loss: 2.495817, acc.: 15.00%] [G loss: 3.573231]\n",
      "288 [D loss: 1.819088, acc.: 30.00%] [G loss: 4.046745]\n",
      "289 [D loss: 1.252375, acc.: 50.00%] [G loss: 4.070977]\n",
      "290 [D loss: 2.153627, acc.: 30.00%] [G loss: 3.034479]\n",
      "291 [D loss: 1.630091, acc.: 40.00%] [G loss: 4.067669]\n",
      "292 [D loss: 1.373253, acc.: 35.00%] [G loss: 2.355115]\n",
      "293 [D loss: 1.292953, acc.: 35.00%] [G loss: 3.054169]\n",
      "294 [D loss: 2.281224, acc.: 25.00%] [G loss: 3.241982]\n",
      "295 [D loss: 0.573692, acc.: 75.00%] [G loss: 1.378265]\n",
      "296 [D loss: 1.955927, acc.: 50.00%] [G loss: 3.366363]\n",
      "297 [D loss: 1.387668, acc.: 55.00%] [G loss: 1.089946]\n",
      "298 [D loss: 1.754537, acc.: 40.00%] [G loss: 0.467583]\n",
      "299 [D loss: 0.993098, acc.: 55.00%] [G loss: 4.909195]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 [D loss: 2.364596, acc.: 40.00%] [G loss: 2.644351]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301 [D loss: 1.198523, acc.: 40.00%] [G loss: 2.113812]\n",
      "302 [D loss: 0.201833, acc.: 95.00%] [G loss: 2.340458]\n",
      "303 [D loss: 0.864058, acc.: 65.00%] [G loss: 4.342439]\n",
      "304 [D loss: 1.089988, acc.: 60.00%] [G loss: 0.710861]\n",
      "305 [D loss: 0.932249, acc.: 65.00%] [G loss: 0.324169]\n",
      "306 [D loss: 0.995274, acc.: 60.00%] [G loss: 6.298322]\n",
      "307 [D loss: 1.312318, acc.: 60.00%] [G loss: 2.257052]\n",
      "308 [D loss: 0.460449, acc.: 70.00%] [G loss: 1.851967]\n",
      "309 [D loss: 0.395307, acc.: 80.00%] [G loss: 2.161045]\n",
      "310 [D loss: 1.359020, acc.: 65.00%] [G loss: 2.279453]\n",
      "311 [D loss: 0.781004, acc.: 55.00%] [G loss: 2.862421]\n",
      "312 [D loss: 1.113933, acc.: 55.00%] [G loss: 3.805864]\n",
      "313 [D loss: 1.920313, acc.: 15.00%] [G loss: 2.954856]\n",
      "314 [D loss: 1.571991, acc.: 45.00%] [G loss: 1.498031]\n",
      "315 [D loss: 1.091613, acc.: 55.00%] [G loss: 2.927980]\n",
      "316 [D loss: 0.838505, acc.: 50.00%] [G loss: 4.121548]\n",
      "317 [D loss: 1.253292, acc.: 55.00%] [G loss: 1.385306]\n",
      "318 [D loss: 0.506295, acc.: 85.00%] [G loss: 0.754344]\n",
      "319 [D loss: 0.983628, acc.: 50.00%] [G loss: 2.232249]\n",
      "320 [D loss: 2.024662, acc.: 15.00%] [G loss: 3.023197]\n",
      "321 [D loss: 0.807705, acc.: 60.00%] [G loss: 1.883595]\n",
      "322 [D loss: 0.767954, acc.: 65.00%] [G loss: 1.821102]\n",
      "323 [D loss: 1.503118, acc.: 50.00%] [G loss: 4.668091]\n",
      "324 [D loss: 2.184551, acc.: 30.00%] [G loss: 4.936850]\n",
      "325 [D loss: 0.625459, acc.: 65.00%] [G loss: 3.095064]\n",
      "326 [D loss: 0.970468, acc.: 50.00%] [G loss: 2.656648]\n",
      "327 [D loss: 1.389781, acc.: 35.00%] [G loss: 3.661740]\n",
      "328 [D loss: 1.462601, acc.: 45.00%] [G loss: 1.859682]\n",
      "329 [D loss: 1.771075, acc.: 30.00%] [G loss: 3.289979]\n",
      "330 [D loss: 1.776577, acc.: 45.00%] [G loss: 1.329088]\n",
      "331 [D loss: 0.881891, acc.: 60.00%] [G loss: 1.672669]\n",
      "332 [D loss: 1.275321, acc.: 45.00%] [G loss: 2.789539]\n",
      "333 [D loss: 1.409960, acc.: 45.00%] [G loss: 1.942131]\n",
      "334 [D loss: 0.822959, acc.: 60.00%] [G loss: 1.171822]\n",
      "335 [D loss: 1.250192, acc.: 60.00%] [G loss: 4.025418]\n",
      "336 [D loss: 1.662657, acc.: 20.00%] [G loss: 2.868371]\n",
      "337 [D loss: 2.183446, acc.: 30.00%] [G loss: 1.499521]\n",
      "338 [D loss: 1.627513, acc.: 30.00%] [G loss: 2.192275]\n",
      "339 [D loss: 0.953245, acc.: 60.00%] [G loss: 3.288871]\n",
      "340 [D loss: 2.238313, acc.: 50.00%] [G loss: 1.947530]\n",
      "341 [D loss: 1.579126, acc.: 40.00%] [G loss: 1.222838]\n",
      "342 [D loss: 1.607180, acc.: 35.00%] [G loss: 3.638669]\n",
      "343 [D loss: 1.379704, acc.: 35.00%] [G loss: 1.753988]\n",
      "344 [D loss: 2.205436, acc.: 10.00%] [G loss: 1.151583]\n",
      "345 [D loss: 0.667187, acc.: 60.00%] [G loss: 4.048888]\n",
      "346 [D loss: 1.531867, acc.: 35.00%] [G loss: 1.775781]\n",
      "347 [D loss: 1.721505, acc.: 30.00%] [G loss: 2.864527]\n",
      "348 [D loss: 1.000653, acc.: 55.00%] [G loss: 1.375870]\n",
      "349 [D loss: 2.322123, acc.: 25.00%] [G loss: 2.674752]\n",
      "350 [D loss: 1.439858, acc.: 40.00%] [G loss: 1.395942]\n",
      "351 [D loss: 0.853552, acc.: 45.00%] [G loss: 1.416989]\n",
      "352 [D loss: 1.312559, acc.: 35.00%] [G loss: 2.676311]\n",
      "353 [D loss: 0.752617, acc.: 55.00%] [G loss: 2.682446]\n",
      "354 [D loss: 1.831371, acc.: 25.00%] [G loss: 1.767926]\n",
      "355 [D loss: 1.306291, acc.: 55.00%] [G loss: 2.442894]\n",
      "356 [D loss: 0.550697, acc.: 65.00%] [G loss: 1.816012]\n",
      "357 [D loss: 1.894690, acc.: 50.00%] [G loss: 2.697686]\n",
      "358 [D loss: 1.262177, acc.: 55.00%] [G loss: 3.022673]\n",
      "359 [D loss: 3.080640, acc.: 10.00%] [G loss: 1.339028]\n",
      "360 [D loss: 1.131180, acc.: 55.00%] [G loss: 3.238483]\n",
      "361 [D loss: 2.287936, acc.: 20.00%] [G loss: 1.463772]\n",
      "362 [D loss: 1.496380, acc.: 55.00%] [G loss: 1.775015]\n",
      "363 [D loss: 1.515290, acc.: 35.00%] [G loss: 3.579132]\n",
      "364 [D loss: 1.879614, acc.: 40.00%] [G loss: 2.790572]\n",
      "365 [D loss: 0.817880, acc.: 55.00%] [G loss: 1.140141]\n",
      "366 [D loss: 1.013196, acc.: 55.00%] [G loss: 3.100824]\n",
      "367 [D loss: 1.997860, acc.: 25.00%] [G loss: 3.034267]\n",
      "368 [D loss: 1.622098, acc.: 25.00%] [G loss: 0.530690]\n",
      "369 [D loss: 1.745752, acc.: 40.00%] [G loss: 1.584245]\n",
      "370 [D loss: 0.751190, acc.: 55.00%] [G loss: 2.355239]\n",
      "371 [D loss: 1.032588, acc.: 60.00%] [G loss: 1.775093]\n",
      "372 [D loss: 0.855145, acc.: 60.00%] [G loss: 2.611784]\n",
      "373 [D loss: 0.835165, acc.: 60.00%] [G loss: 3.193016]\n",
      "374 [D loss: 1.741455, acc.: 25.00%] [G loss: 1.410600]\n",
      "375 [D loss: 1.447039, acc.: 35.00%] [G loss: 2.317476]\n",
      "376 [D loss: 1.347159, acc.: 50.00%] [G loss: 3.825515]\n",
      "377 [D loss: 1.756045, acc.: 25.00%] [G loss: 2.255893]\n",
      "378 [D loss: 1.018054, acc.: 45.00%] [G loss: 1.459817]\n",
      "379 [D loss: 1.610288, acc.: 15.00%] [G loss: 2.368116]\n",
      "380 [D loss: 1.769341, acc.: 35.00%] [G loss: 2.731808]\n",
      "381 [D loss: 1.416055, acc.: 35.00%] [G loss: 1.231223]\n",
      "382 [D loss: 1.781723, acc.: 30.00%] [G loss: 1.320229]\n",
      "383 [D loss: 0.628564, acc.: 70.00%] [G loss: 2.116695]\n",
      "384 [D loss: 1.199967, acc.: 40.00%] [G loss: 1.164413]\n",
      "385 [D loss: 1.590337, acc.: 35.00%] [G loss: 2.616101]\n",
      "386 [D loss: 1.972695, acc.: 20.00%] [G loss: 2.547865]\n",
      "387 [D loss: 1.671247, acc.: 25.00%] [G loss: 2.762978]\n",
      "388 [D loss: 2.265957, acc.: 20.00%] [G loss: 2.190180]\n",
      "389 [D loss: 0.966985, acc.: 55.00%] [G loss: 0.462852]\n",
      "390 [D loss: 1.305132, acc.: 60.00%] [G loss: 4.129279]\n",
      "391 [D loss: 2.016768, acc.: 35.00%] [G loss: 3.093401]\n",
      "392 [D loss: 0.930876, acc.: 70.00%] [G loss: 1.133830]\n",
      "393 [D loss: 1.473150, acc.: 35.00%] [G loss: 0.899623]\n",
      "394 [D loss: 0.929959, acc.: 45.00%] [G loss: 1.748810]\n",
      "395 [D loss: 0.778630, acc.: 70.00%] [G loss: 1.839527]\n",
      "396 [D loss: 1.487588, acc.: 45.00%] [G loss: 3.283506]\n",
      "397 [D loss: 1.962530, acc.: 25.00%] [G loss: 0.777434]\n",
      "398 [D loss: 1.927014, acc.: 35.00%] [G loss: 2.403067]\n",
      "399 [D loss: 1.368079, acc.: 35.00%] [G loss: 2.176070]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 [D loss: 1.669129, acc.: 45.00%] [G loss: 2.154066]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401 [D loss: 1.791475, acc.: 25.00%] [G loss: 2.538171]\n",
      "402 [D loss: 1.443172, acc.: 50.00%] [G loss: 2.652269]\n",
      "403 [D loss: 1.343696, acc.: 35.00%] [G loss: 1.333525]\n",
      "404 [D loss: 1.794105, acc.: 20.00%] [G loss: 3.029503]\n",
      "405 [D loss: 1.683012, acc.: 10.00%] [G loss: 2.366899]\n",
      "406 [D loss: 1.906327, acc.: 15.00%] [G loss: 1.877868]\n",
      "407 [D loss: 2.697412, acc.: 0.00%] [G loss: 2.673443]\n",
      "408 [D loss: 1.495490, acc.: 45.00%] [G loss: 1.948040]\n",
      "409 [D loss: 1.887463, acc.: 25.00%] [G loss: 2.091137]\n",
      "410 [D loss: 2.390186, acc.: 5.00%] [G loss: 2.679672]\n",
      "411 [D loss: 1.977434, acc.: 15.00%] [G loss: 2.021827]\n",
      "412 [D loss: 1.019499, acc.: 50.00%] [G loss: 2.517535]\n",
      "413 [D loss: 1.086263, acc.: 30.00%] [G loss: 1.701619]\n",
      "414 [D loss: 1.024887, acc.: 25.00%] [G loss: 2.960147]\n",
      "415 [D loss: 1.571326, acc.: 30.00%] [G loss: 0.998327]\n",
      "416 [D loss: 2.073031, acc.: 20.00%] [G loss: 1.831504]\n",
      "417 [D loss: 1.750139, acc.: 15.00%] [G loss: 3.452722]\n",
      "418 [D loss: 2.238914, acc.: 25.00%] [G loss: 3.376153]\n",
      "419 [D loss: 1.954608, acc.: 10.00%] [G loss: 1.182745]\n",
      "420 [D loss: 1.292261, acc.: 45.00%] [G loss: 2.015024]\n",
      "421 [D loss: 1.606747, acc.: 10.00%] [G loss: 1.892736]\n",
      "422 [D loss: 1.565763, acc.: 20.00%] [G loss: 2.053773]\n",
      "423 [D loss: 1.899041, acc.: 15.00%] [G loss: 1.825981]\n",
      "424 [D loss: 2.021113, acc.: 20.00%] [G loss: 2.363485]\n",
      "425 [D loss: 2.173254, acc.: 20.00%] [G loss: 2.153766]\n",
      "426 [D loss: 0.815641, acc.: 60.00%] [G loss: 2.556902]\n",
      "427 [D loss: 2.092950, acc.: 40.00%] [G loss: 0.843512]\n",
      "428 [D loss: 0.903066, acc.: 50.00%] [G loss: 0.155710]\n",
      "429 [D loss: 1.241912, acc.: 60.00%] [G loss: 2.676295]\n",
      "430 [D loss: 1.114342, acc.: 50.00%] [G loss: 2.707551]\n",
      "431 [D loss: 2.310906, acc.: 15.00%] [G loss: 2.101129]\n",
      "432 [D loss: 1.869093, acc.: 30.00%] [G loss: 2.208896]\n",
      "433 [D loss: 1.945032, acc.: 20.00%] [G loss: 1.959767]\n",
      "434 [D loss: 1.580288, acc.: 35.00%] [G loss: 1.539173]\n",
      "435 [D loss: 1.850376, acc.: 20.00%] [G loss: 1.495971]\n",
      "436 [D loss: 1.410094, acc.: 25.00%] [G loss: 2.169729]\n",
      "437 [D loss: 1.249739, acc.: 40.00%] [G loss: 2.864071]\n",
      "438 [D loss: 1.524657, acc.: 35.00%] [G loss: 1.819554]\n",
      "439 [D loss: 1.318328, acc.: 40.00%] [G loss: 1.800863]\n",
      "440 [D loss: 1.948815, acc.: 5.00%] [G loss: 1.833140]\n",
      "441 [D loss: 1.647808, acc.: 45.00%] [G loss: 1.830283]\n",
      "442 [D loss: 1.387236, acc.: 35.00%] [G loss: 3.071532]\n",
      "443 [D loss: 1.613644, acc.: 30.00%] [G loss: 0.976308]\n",
      "444 [D loss: 2.237001, acc.: 15.00%] [G loss: 1.448669]\n",
      "445 [D loss: 0.858001, acc.: 65.00%] [G loss: 2.161036]\n",
      "446 [D loss: 1.386976, acc.: 50.00%] [G loss: 1.619999]\n",
      "447 [D loss: 1.765320, acc.: 25.00%] [G loss: 2.575758]\n",
      "448 [D loss: 1.134576, acc.: 45.00%] [G loss: 3.871097]\n",
      "449 [D loss: 1.960501, acc.: 35.00%] [G loss: 0.723237]\n",
      "450 [D loss: 0.925964, acc.: 65.00%] [G loss: 1.981374]\n",
      "451 [D loss: 0.866717, acc.: 60.00%] [G loss: 1.369343]\n",
      "452 [D loss: 1.854586, acc.: 45.00%] [G loss: 2.117203]\n",
      "453 [D loss: 1.453626, acc.: 35.00%] [G loss: 3.235939]\n",
      "454 [D loss: 1.324711, acc.: 45.00%] [G loss: 2.736800]\n",
      "455 [D loss: 1.455567, acc.: 35.00%] [G loss: 3.163835]\n",
      "456 [D loss: 1.612823, acc.: 25.00%] [G loss: 3.241498]\n",
      "457 [D loss: 1.527793, acc.: 20.00%] [G loss: 2.300468]\n",
      "458 [D loss: 1.711501, acc.: 35.00%] [G loss: 2.018394]\n",
      "459 [D loss: 1.830757, acc.: 10.00%] [G loss: 2.979655]\n",
      "460 [D loss: 1.581502, acc.: 30.00%] [G loss: 1.473216]\n",
      "461 [D loss: 1.679426, acc.: 40.00%] [G loss: 1.348681]\n",
      "462 [D loss: 1.115582, acc.: 45.00%] [G loss: 2.104527]\n",
      "463 [D loss: 2.439816, acc.: 20.00%] [G loss: 1.327702]\n",
      "464 [D loss: 2.013988, acc.: 20.00%] [G loss: 2.101033]\n",
      "465 [D loss: 1.142871, acc.: 55.00%] [G loss: 1.260189]\n",
      "466 [D loss: 2.287812, acc.: 35.00%] [G loss: 1.565632]\n",
      "467 [D loss: 1.238895, acc.: 45.00%] [G loss: 2.429700]\n",
      "468 [D loss: 1.003196, acc.: 65.00%] [G loss: 1.496369]\n",
      "469 [D loss: 0.804158, acc.: 55.00%] [G loss: 0.748491]\n",
      "470 [D loss: 1.515536, acc.: 40.00%] [G loss: 1.204267]\n",
      "471 [D loss: 0.872256, acc.: 60.00%] [G loss: 4.552865]\n",
      "472 [D loss: 1.282865, acc.: 50.00%] [G loss: 2.072461]\n",
      "473 [D loss: 1.901223, acc.: 35.00%] [G loss: 2.009774]\n",
      "474 [D loss: 1.416064, acc.: 45.00%] [G loss: 1.087001]\n",
      "475 [D loss: 1.361939, acc.: 35.00%] [G loss: 1.294690]\n",
      "476 [D loss: 1.420137, acc.: 40.00%] [G loss: 1.994242]\n",
      "477 [D loss: 2.145344, acc.: 15.00%] [G loss: 2.743273]\n",
      "478 [D loss: 1.696453, acc.: 10.00%] [G loss: 2.235352]\n",
      "479 [D loss: 1.876787, acc.: 20.00%] [G loss: 1.714072]\n",
      "480 [D loss: 1.511460, acc.: 30.00%] [G loss: 2.313850]\n",
      "481 [D loss: 1.871433, acc.: 25.00%] [G loss: 2.080775]\n",
      "482 [D loss: 1.623157, acc.: 30.00%] [G loss: 1.627025]\n",
      "483 [D loss: 1.581225, acc.: 35.00%] [G loss: 2.938253]\n",
      "484 [D loss: 1.346426, acc.: 35.00%] [G loss: 1.734720]\n",
      "485 [D loss: 1.307411, acc.: 45.00%] [G loss: 1.655268]\n",
      "486 [D loss: 1.120818, acc.: 50.00%] [G loss: 1.471536]\n",
      "487 [D loss: 1.351309, acc.: 35.00%] [G loss: 2.441343]\n",
      "488 [D loss: 0.870901, acc.: 50.00%] [G loss: 1.768088]\n",
      "489 [D loss: 0.858002, acc.: 60.00%] [G loss: 1.554054]\n",
      "490 [D loss: 0.715956, acc.: 50.00%] [G loss: 1.339021]\n",
      "491 [D loss: 1.903141, acc.: 25.00%] [G loss: 0.817006]\n",
      "492 [D loss: 1.488945, acc.: 45.00%] [G loss: 2.913384]\n",
      "493 [D loss: 1.538792, acc.: 35.00%] [G loss: 1.357157]\n",
      "494 [D loss: 1.669497, acc.: 30.00%] [G loss: 0.631948]\n",
      "495 [D loss: 1.277701, acc.: 45.00%] [G loss: 1.601303]\n",
      "496 [D loss: 1.327580, acc.: 30.00%] [G loss: 2.238349]\n",
      "497 [D loss: 1.601308, acc.: 15.00%] [G loss: 1.635705]\n",
      "498 [D loss: 0.895052, acc.: 60.00%] [G loss: 2.433753]\n",
      "499 [D loss: 0.872965, acc.: 60.00%] [G loss: 1.823001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 [D loss: 1.528330, acc.: 35.00%] [G loss: 2.091713]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501 [D loss: 1.040555, acc.: 50.00%] [G loss: 2.367627]\n",
      "502 [D loss: 1.595320, acc.: 45.00%] [G loss: 1.450971]\n",
      "503 [D loss: 1.313738, acc.: 20.00%] [G loss: 0.695324]\n",
      "504 [D loss: 0.497617, acc.: 80.00%] [G loss: 0.882002]\n",
      "505 [D loss: 0.953408, acc.: 50.00%] [G loss: 0.858652]\n",
      "506 [D loss: 1.198544, acc.: 55.00%] [G loss: 1.484873]\n",
      "507 [D loss: 1.462082, acc.: 30.00%] [G loss: 2.482619]\n",
      "508 [D loss: 1.567442, acc.: 40.00%] [G loss: 2.290915]\n",
      "509 [D loss: 1.172451, acc.: 65.00%] [G loss: 1.338732]\n",
      "510 [D loss: 0.947150, acc.: 55.00%] [G loss: 1.085409]\n",
      "511 [D loss: 1.161312, acc.: 45.00%] [G loss: 2.671762]\n",
      "512 [D loss: 1.199077, acc.: 40.00%] [G loss: 2.448308]\n",
      "513 [D loss: 2.109575, acc.: 30.00%] [G loss: 0.852486]\n",
      "514 [D loss: 1.316607, acc.: 30.00%] [G loss: 1.147036]\n",
      "515 [D loss: 1.004380, acc.: 40.00%] [G loss: 2.041126]\n",
      "516 [D loss: 1.132679, acc.: 35.00%] [G loss: 2.440022]\n",
      "517 [D loss: 1.810785, acc.: 10.00%] [G loss: 2.427323]\n",
      "518 [D loss: 1.515663, acc.: 35.00%] [G loss: 2.908971]\n",
      "519 [D loss: 1.429357, acc.: 35.00%] [G loss: 2.114480]\n",
      "520 [D loss: 1.309681, acc.: 40.00%] [G loss: 1.266344]\n",
      "521 [D loss: 0.773314, acc.: 60.00%] [G loss: 0.996168]\n",
      "522 [D loss: 1.579046, acc.: 45.00%] [G loss: 2.758273]\n",
      "523 [D loss: 0.613677, acc.: 70.00%] [G loss: 2.955079]\n",
      "524 [D loss: 0.840546, acc.: 60.00%] [G loss: 1.849552]\n",
      "525 [D loss: 0.388713, acc.: 80.00%] [G loss: 2.497341]\n",
      "526 [D loss: 1.683011, acc.: 40.00%] [G loss: 1.667649]\n",
      "527 [D loss: 1.115630, acc.: 40.00%] [G loss: 2.582244]\n",
      "528 [D loss: 1.852693, acc.: 25.00%] [G loss: 1.661317]\n",
      "529 [D loss: 0.881350, acc.: 55.00%] [G loss: 2.479898]\n",
      "530 [D loss: 1.199470, acc.: 40.00%] [G loss: 2.541530]\n",
      "531 [D loss: 1.007394, acc.: 70.00%] [G loss: 2.541461]\n",
      "532 [D loss: 1.838177, acc.: 25.00%] [G loss: 1.133031]\n",
      "533 [D loss: 1.282178, acc.: 35.00%] [G loss: 2.695878]\n",
      "534 [D loss: 1.571055, acc.: 30.00%] [G loss: 2.462791]\n",
      "535 [D loss: 1.748116, acc.: 20.00%] [G loss: 1.235975]\n",
      "536 [D loss: 1.477441, acc.: 45.00%] [G loss: 2.384233]\n",
      "537 [D loss: 1.627704, acc.: 20.00%] [G loss: 0.986764]\n",
      "538 [D loss: 1.521510, acc.: 40.00%] [G loss: 2.452293]\n",
      "539 [D loss: 0.642659, acc.: 75.00%] [G loss: 0.903632]\n",
      "540 [D loss: 1.096650, acc.: 50.00%] [G loss: 0.585973]\n",
      "541 [D loss: 1.218493, acc.: 60.00%] [G loss: 2.724219]\n",
      "542 [D loss: 1.325185, acc.: 20.00%] [G loss: 2.137809]\n",
      "543 [D loss: 1.717135, acc.: 45.00%] [G loss: 0.945974]\n",
      "544 [D loss: 1.793236, acc.: 35.00%] [G loss: 1.936113]\n",
      "545 [D loss: 1.503926, acc.: 30.00%] [G loss: 1.828667]\n",
      "546 [D loss: 1.092058, acc.: 40.00%] [G loss: 1.471365]\n",
      "547 [D loss: 0.861706, acc.: 55.00%] [G loss: 2.466366]\n",
      "548 [D loss: 1.545189, acc.: 45.00%] [G loss: 2.473097]\n",
      "549 [D loss: 2.061427, acc.: 10.00%] [G loss: 1.861031]\n",
      "550 [D loss: 1.497811, acc.: 25.00%] [G loss: 1.448542]\n",
      "551 [D loss: 0.983012, acc.: 55.00%] [G loss: 1.030386]\n",
      "552 [D loss: 0.965438, acc.: 55.00%] [G loss: 1.667660]\n",
      "553 [D loss: 1.846584, acc.: 30.00%] [G loss: 3.277910]\n",
      "554 [D loss: 1.907840, acc.: 20.00%] [G loss: 1.875131]\n",
      "555 [D loss: 1.099369, acc.: 45.00%] [G loss: 1.238436]\n",
      "556 [D loss: 1.472097, acc.: 20.00%] [G loss: 2.371989]\n",
      "557 [D loss: 1.172696, acc.: 40.00%] [G loss: 0.693543]\n",
      "558 [D loss: 1.239385, acc.: 55.00%] [G loss: 1.664097]\n",
      "559 [D loss: 0.960595, acc.: 60.00%] [G loss: 1.115701]\n",
      "560 [D loss: 1.714685, acc.: 40.00%] [G loss: 2.343663]\n",
      "561 [D loss: 1.400883, acc.: 25.00%] [G loss: 2.971514]\n",
      "562 [D loss: 1.355455, acc.: 45.00%] [G loss: 2.017502]\n",
      "563 [D loss: 1.336516, acc.: 25.00%] [G loss: 1.252706]\n",
      "564 [D loss: 2.254777, acc.: 25.00%] [G loss: 1.420635]\n",
      "565 [D loss: 0.621637, acc.: 70.00%] [G loss: 2.358073]\n",
      "566 [D loss: 1.721016, acc.: 25.00%] [G loss: 1.513872]\n",
      "567 [D loss: 1.611832, acc.: 40.00%] [G loss: 2.538735]\n",
      "568 [D loss: 1.301349, acc.: 30.00%] [G loss: 3.206011]\n",
      "569 [D loss: 0.896364, acc.: 65.00%] [G loss: 2.995897]\n",
      "570 [D loss: 2.202205, acc.: 15.00%] [G loss: 1.570365]\n",
      "571 [D loss: 1.007628, acc.: 55.00%] [G loss: 2.650580]\n",
      "572 [D loss: 1.187504, acc.: 55.00%] [G loss: 2.519309]\n",
      "573 [D loss: 1.882096, acc.: 30.00%] [G loss: 1.651114]\n",
      "574 [D loss: 1.773105, acc.: 40.00%] [G loss: 1.825312]\n",
      "575 [D loss: 1.992113, acc.: 10.00%] [G loss: 2.308779]\n",
      "576 [D loss: 1.191140, acc.: 40.00%] [G loss: 2.957736]\n",
      "577 [D loss: 2.208119, acc.: 30.00%] [G loss: 0.981036]\n",
      "578 [D loss: 0.513223, acc.: 70.00%] [G loss: 2.295407]\n",
      "579 [D loss: 1.112773, acc.: 35.00%] [G loss: 2.091814]\n",
      "580 [D loss: 0.895258, acc.: 50.00%] [G loss: 1.635365]\n",
      "581 [D loss: 1.596916, acc.: 30.00%] [G loss: 0.590752]\n",
      "582 [D loss: 1.017502, acc.: 70.00%] [G loss: 1.583777]\n",
      "583 [D loss: 1.106261, acc.: 45.00%] [G loss: 3.719122]\n",
      "584 [D loss: 2.037911, acc.: 30.00%] [G loss: 2.112703]\n",
      "585 [D loss: 2.517600, acc.: 20.00%] [G loss: 1.251497]\n",
      "586 [D loss: 1.925842, acc.: 35.00%] [G loss: 2.208538]\n",
      "587 [D loss: 1.257138, acc.: 50.00%] [G loss: 1.340887]\n",
      "588 [D loss: 1.382614, acc.: 35.00%] [G loss: 1.837743]\n",
      "589 [D loss: 1.429592, acc.: 35.00%] [G loss: 2.029733]\n",
      "590 [D loss: 1.030197, acc.: 55.00%] [G loss: 3.181669]\n",
      "591 [D loss: 2.017158, acc.: 25.00%] [G loss: 1.860241]\n",
      "592 [D loss: 2.080715, acc.: 20.00%] [G loss: 0.976129]\n",
      "593 [D loss: 1.986959, acc.: 25.00%] [G loss: 2.175123]\n",
      "594 [D loss: 0.980272, acc.: 60.00%] [G loss: 1.035881]\n",
      "595 [D loss: 0.839307, acc.: 65.00%] [G loss: 2.329319]\n",
      "596 [D loss: 1.662535, acc.: 20.00%] [G loss: 2.504204]\n",
      "597 [D loss: 0.903727, acc.: 60.00%] [G loss: 2.543417]\n",
      "598 [D loss: 1.713515, acc.: 25.00%] [G loss: 1.734878]\n",
      "599 [D loss: 0.939108, acc.: 55.00%] [G loss: 2.002661]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 [D loss: 1.337090, acc.: 55.00%] [G loss: 1.160894]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601 [D loss: 1.623419, acc.: 35.00%] [G loss: 1.020687]\n",
      "602 [D loss: 1.010836, acc.: 60.00%] [G loss: 2.487713]\n",
      "603 [D loss: 1.909493, acc.: 20.00%] [G loss: 2.435679]\n",
      "604 [D loss: 2.476531, acc.: 10.00%] [G loss: 2.541735]\n",
      "605 [D loss: 1.567809, acc.: 20.00%] [G loss: 2.311639]\n",
      "606 [D loss: 1.177019, acc.: 45.00%] [G loss: 1.335420]\n",
      "607 [D loss: 1.902226, acc.: 25.00%] [G loss: 1.441329]\n",
      "608 [D loss: 0.913165, acc.: 60.00%] [G loss: 1.654116]\n",
      "609 [D loss: 1.162683, acc.: 50.00%] [G loss: 1.859796]\n",
      "610 [D loss: 1.056136, acc.: 40.00%] [G loss: 1.265969]\n",
      "611 [D loss: 0.550654, acc.: 70.00%] [G loss: 1.927338]\n",
      "612 [D loss: 1.985571, acc.: 40.00%] [G loss: 1.744476]\n",
      "613 [D loss: 0.534269, acc.: 80.00%] [G loss: 2.064510]\n",
      "614 [D loss: 2.153448, acc.: 20.00%] [G loss: 1.323279]\n",
      "615 [D loss: 1.082130, acc.: 50.00%] [G loss: 1.705562]\n",
      "616 [D loss: 1.284167, acc.: 40.00%] [G loss: 1.738642]\n",
      "617 [D loss: 1.273933, acc.: 25.00%] [G loss: 1.890568]\n",
      "618 [D loss: 0.940728, acc.: 50.00%] [G loss: 3.413081]\n",
      "619 [D loss: 1.661803, acc.: 50.00%] [G loss: 1.916263]\n",
      "620 [D loss: 1.613400, acc.: 40.00%] [G loss: 1.297793]\n",
      "621 [D loss: 1.042726, acc.: 45.00%] [G loss: 1.111283]\n",
      "622 [D loss: 0.822808, acc.: 50.00%] [G loss: 1.894294]\n",
      "623 [D loss: 1.194270, acc.: 50.00%] [G loss: 3.877882]\n",
      "624 [D loss: 1.491903, acc.: 45.00%] [G loss: 0.946175]\n",
      "625 [D loss: 1.470937, acc.: 30.00%] [G loss: 1.550826]\n",
      "626 [D loss: 1.138568, acc.: 45.00%] [G loss: 2.013326]\n",
      "627 [D loss: 1.608871, acc.: 35.00%] [G loss: 1.295223]\n",
      "628 [D loss: 2.233517, acc.: 10.00%] [G loss: 2.025391]\n",
      "629 [D loss: 0.918794, acc.: 70.00%] [G loss: 2.682290]\n",
      "630 [D loss: 1.447987, acc.: 40.00%] [G loss: 1.551709]\n",
      "631 [D loss: 1.494083, acc.: 20.00%] [G loss: 1.951213]\n",
      "632 [D loss: 1.134503, acc.: 45.00%] [G loss: 1.474169]\n",
      "633 [D loss: 1.309663, acc.: 40.00%] [G loss: 1.514041]\n",
      "634 [D loss: 1.168123, acc.: 50.00%] [G loss: 2.286701]\n",
      "635 [D loss: 1.319204, acc.: 40.00%] [G loss: 0.802608]\n",
      "636 [D loss: 1.550461, acc.: 30.00%] [G loss: 2.398425]\n",
      "637 [D loss: 0.879430, acc.: 60.00%] [G loss: 2.296456]\n",
      "638 [D loss: 2.043964, acc.: 30.00%] [G loss: 1.982070]\n",
      "639 [D loss: 1.199488, acc.: 45.00%] [G loss: 2.663459]\n",
      "640 [D loss: 1.135158, acc.: 50.00%] [G loss: 1.459414]\n",
      "641 [D loss: 1.173250, acc.: 35.00%] [G loss: 2.042241]\n",
      "642 [D loss: 1.456478, acc.: 35.00%] [G loss: 1.453834]\n",
      "643 [D loss: 0.865610, acc.: 60.00%] [G loss: 1.625490]\n",
      "644 [D loss: 1.756670, acc.: 30.00%] [G loss: 2.760185]\n",
      "645 [D loss: 1.542732, acc.: 25.00%] [G loss: 1.857643]\n",
      "646 [D loss: 0.620896, acc.: 70.00%] [G loss: 0.955605]\n",
      "647 [D loss: 1.493313, acc.: 35.00%] [G loss: 2.413239]\n",
      "648 [D loss: 1.697995, acc.: 20.00%] [G loss: 2.878353]\n",
      "649 [D loss: 1.456303, acc.: 50.00%] [G loss: 0.416747]\n",
      "650 [D loss: 0.715177, acc.: 65.00%] [G loss: 0.739552]\n",
      "651 [D loss: 1.372172, acc.: 50.00%] [G loss: 2.281604]\n",
      "652 [D loss: 1.610404, acc.: 40.00%] [G loss: 2.672355]\n",
      "653 [D loss: 1.975474, acc.: 20.00%] [G loss: 1.387139]\n",
      "654 [D loss: 1.611070, acc.: 35.00%] [G loss: 1.679749]\n",
      "655 [D loss: 1.068941, acc.: 55.00%] [G loss: 2.071321]\n",
      "656 [D loss: 1.432888, acc.: 50.00%] [G loss: 2.285111]\n",
      "657 [D loss: 1.381680, acc.: 30.00%] [G loss: 1.874404]\n",
      "658 [D loss: 1.383077, acc.: 30.00%] [G loss: 2.443418]\n",
      "659 [D loss: 1.418758, acc.: 40.00%] [G loss: 0.813215]\n",
      "660 [D loss: 1.272606, acc.: 55.00%] [G loss: 1.807852]\n",
      "661 [D loss: 1.204322, acc.: 50.00%] [G loss: 1.532355]\n",
      "662 [D loss: 2.416136, acc.: 25.00%] [G loss: 0.674682]\n",
      "663 [D loss: 0.769719, acc.: 55.00%] [G loss: 2.536635]\n",
      "664 [D loss: 1.137402, acc.: 35.00%] [G loss: 2.117633]\n",
      "665 [D loss: 1.844372, acc.: 20.00%] [G loss: 1.927407]\n",
      "666 [D loss: 1.097886, acc.: 35.00%] [G loss: 2.551054]\n",
      "667 [D loss: 1.165011, acc.: 45.00%] [G loss: 2.383111]\n",
      "668 [D loss: 0.842822, acc.: 65.00%] [G loss: 3.541409]\n",
      "669 [D loss: 1.745631, acc.: 30.00%] [G loss: 2.747290]\n",
      "670 [D loss: 1.437477, acc.: 25.00%] [G loss: 1.676849]\n",
      "671 [D loss: 1.352946, acc.: 50.00%] [G loss: 3.218784]\n",
      "672 [D loss: 0.864309, acc.: 50.00%] [G loss: 2.753504]\n",
      "673 [D loss: 1.134540, acc.: 40.00%] [G loss: 1.290808]\n",
      "674 [D loss: 1.062014, acc.: 65.00%] [G loss: 0.910096]\n",
      "675 [D loss: 1.095307, acc.: 55.00%] [G loss: 0.875997]\n",
      "676 [D loss: 0.860219, acc.: 50.00%] [G loss: 2.425504]\n",
      "677 [D loss: 0.835670, acc.: 65.00%] [G loss: 0.463743]\n",
      "678 [D loss: 0.936981, acc.: 50.00%] [G loss: 0.416463]\n",
      "679 [D loss: 0.392919, acc.: 85.00%] [G loss: 0.388919]\n",
      "680 [D loss: 0.566647, acc.: 80.00%] [G loss: 1.170514]\n",
      "681 [D loss: 1.155238, acc.: 45.00%] [G loss: 2.619647]\n",
      "682 [D loss: 1.139510, acc.: 60.00%] [G loss: 0.863578]\n",
      "683 [D loss: 0.598623, acc.: 70.00%] [G loss: 0.688919]\n",
      "684 [D loss: 1.496930, acc.: 50.00%] [G loss: 1.646380]\n",
      "685 [D loss: 1.370089, acc.: 50.00%] [G loss: 2.199694]\n",
      "686 [D loss: 1.403431, acc.: 40.00%] [G loss: 0.979852]\n",
      "687 [D loss: 1.011360, acc.: 65.00%] [G loss: 2.219503]\n",
      "688 [D loss: 0.948480, acc.: 60.00%] [G loss: 0.595304]\n",
      "689 [D loss: 1.153582, acc.: 40.00%] [G loss: 1.969378]\n",
      "690 [D loss: 0.857388, acc.: 70.00%] [G loss: 1.352601]\n",
      "691 [D loss: 0.905679, acc.: 45.00%] [G loss: 2.469322]\n",
      "692 [D loss: 0.796144, acc.: 65.00%] [G loss: 0.697912]\n",
      "693 [D loss: 1.347275, acc.: 40.00%] [G loss: 1.409779]\n",
      "694 [D loss: 0.862424, acc.: 55.00%] [G loss: 2.580032]\n",
      "695 [D loss: 1.211725, acc.: 40.00%] [G loss: 2.863791]\n",
      "696 [D loss: 1.250316, acc.: 45.00%] [G loss: 3.136132]\n",
      "697 [D loss: 1.549115, acc.: 50.00%] [G loss: 0.973795]\n",
      "698 [D loss: 0.930356, acc.: 60.00%] [G loss: 2.230331]\n",
      "699 [D loss: 0.660692, acc.: 60.00%] [G loss: 1.899141]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700 [D loss: 1.082461, acc.: 55.00%] [G loss: 1.332003]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701 [D loss: 0.583979, acc.: 75.00%] [G loss: 3.402044]\n",
      "702 [D loss: 1.625371, acc.: 50.00%] [G loss: 0.837192]\n",
      "703 [D loss: 0.268766, acc.: 100.00%] [G loss: 1.547261]\n",
      "704 [D loss: 1.291247, acc.: 45.00%] [G loss: 3.440836]\n",
      "705 [D loss: 1.491705, acc.: 55.00%] [G loss: 2.265820]\n",
      "706 [D loss: 1.098042, acc.: 50.00%] [G loss: 0.465346]\n",
      "707 [D loss: 0.757766, acc.: 50.00%] [G loss: 1.039733]\n",
      "708 [D loss: 1.278655, acc.: 50.00%] [G loss: 1.886936]\n",
      "709 [D loss: 1.310346, acc.: 35.00%] [G loss: 1.803382]\n",
      "710 [D loss: 1.551393, acc.: 35.00%] [G loss: 1.143871]\n",
      "711 [D loss: 0.654919, acc.: 60.00%] [G loss: 0.669291]\n",
      "712 [D loss: 1.344676, acc.: 55.00%] [G loss: 1.867206]\n",
      "713 [D loss: 1.298393, acc.: 35.00%] [G loss: 3.291175]\n",
      "714 [D loss: 1.715529, acc.: 35.00%] [G loss: 1.731210]\n",
      "715 [D loss: 1.521980, acc.: 15.00%] [G loss: 2.994862]\n",
      "716 [D loss: 0.461917, acc.: 70.00%] [G loss: 2.585596]\n",
      "717 [D loss: 1.784027, acc.: 20.00%] [G loss: 1.931852]\n",
      "718 [D loss: 0.971958, acc.: 60.00%] [G loss: 2.919906]\n",
      "719 [D loss: 0.942650, acc.: 50.00%] [G loss: 2.075146]\n",
      "720 [D loss: 1.439513, acc.: 35.00%] [G loss: 1.673692]\n",
      "721 [D loss: 0.728859, acc.: 55.00%] [G loss: 3.327118]\n",
      "722 [D loss: 0.624050, acc.: 55.00%] [G loss: 2.980302]\n",
      "723 [D loss: 2.489069, acc.: 10.00%] [G loss: 2.334124]\n",
      "724 [D loss: 0.982927, acc.: 70.00%] [G loss: 1.574313]\n",
      "725 [D loss: 1.062585, acc.: 60.00%] [G loss: 1.729929]\n",
      "726 [D loss: 1.184833, acc.: 45.00%] [G loss: 2.363956]\n",
      "727 [D loss: 1.025691, acc.: 45.00%] [G loss: 2.309859]\n",
      "728 [D loss: 0.834336, acc.: 65.00%] [G loss: 1.943048]\n",
      "729 [D loss: 1.515807, acc.: 30.00%] [G loss: 2.041065]\n",
      "730 [D loss: 0.922386, acc.: 40.00%] [G loss: 2.191642]\n",
      "731 [D loss: 1.534142, acc.: 40.00%] [G loss: 1.805361]\n",
      "732 [D loss: 1.257685, acc.: 35.00%] [G loss: 1.539129]\n",
      "733 [D loss: 1.624078, acc.: 30.00%] [G loss: 1.419449]\n",
      "734 [D loss: 0.316201, acc.: 90.00%] [G loss: 1.714545]\n",
      "735 [D loss: 1.640459, acc.: 30.00%] [G loss: 2.143852]\n",
      "736 [D loss: 1.250365, acc.: 35.00%] [G loss: 1.357046]\n",
      "737 [D loss: 0.905650, acc.: 65.00%] [G loss: 1.321890]\n",
      "738 [D loss: 0.841832, acc.: 55.00%] [G loss: 1.946460]\n",
      "739 [D loss: 1.298067, acc.: 40.00%] [G loss: 2.925738]\n",
      "740 [D loss: 1.273762, acc.: 35.00%] [G loss: 3.398464]\n",
      "741 [D loss: 0.939346, acc.: 45.00%] [G loss: 2.239694]\n",
      "742 [D loss: 1.760006, acc.: 30.00%] [G loss: 1.483490]\n",
      "743 [D loss: 1.106257, acc.: 35.00%] [G loss: 2.570028]\n",
      "744 [D loss: 1.166334, acc.: 50.00%] [G loss: 1.897387]\n",
      "745 [D loss: 1.197713, acc.: 25.00%] [G loss: 2.279873]\n",
      "746 [D loss: 1.817088, acc.: 40.00%] [G loss: 2.633196]\n",
      "747 [D loss: 1.287110, acc.: 45.00%] [G loss: 2.205319]\n",
      "748 [D loss: 1.028841, acc.: 50.00%] [G loss: 1.315610]\n",
      "749 [D loss: 0.946387, acc.: 45.00%] [G loss: 2.207608]\n",
      "750 [D loss: 0.720910, acc.: 75.00%] [G loss: 2.042320]\n",
      "751 [D loss: 0.920292, acc.: 50.00%] [G loss: 2.230478]\n",
      "752 [D loss: 0.852458, acc.: 40.00%] [G loss: 2.225983]\n",
      "753 [D loss: 0.689476, acc.: 70.00%] [G loss: 1.450242]\n",
      "754 [D loss: 0.973437, acc.: 45.00%] [G loss: 2.435430]\n",
      "755 [D loss: 0.685284, acc.: 60.00%] [G loss: 1.415694]\n",
      "756 [D loss: 1.034830, acc.: 50.00%] [G loss: 1.759389]\n",
      "757 [D loss: 0.943557, acc.: 60.00%] [G loss: 0.760784]\n",
      "758 [D loss: 1.221031, acc.: 40.00%] [G loss: 3.156453]\n",
      "759 [D loss: 0.981946, acc.: 55.00%] [G loss: 1.273923]\n",
      "760 [D loss: 1.523129, acc.: 35.00%] [G loss: 1.472263]\n",
      "761 [D loss: 0.913235, acc.: 65.00%] [G loss: 2.344369]\n",
      "762 [D loss: 1.891913, acc.: 10.00%] [G loss: 2.767035]\n",
      "763 [D loss: 1.044836, acc.: 40.00%] [G loss: 1.937147]\n",
      "764 [D loss: 1.096735, acc.: 50.00%] [G loss: 2.173267]\n",
      "765 [D loss: 1.333902, acc.: 55.00%] [G loss: 2.766312]\n",
      "766 [D loss: 1.272503, acc.: 45.00%] [G loss: 2.126085]\n",
      "767 [D loss: 1.181085, acc.: 50.00%] [G loss: 1.060008]\n",
      "768 [D loss: 1.114454, acc.: 50.00%] [G loss: 1.738004]\n",
      "769 [D loss: 1.041326, acc.: 60.00%] [G loss: 1.917243]\n",
      "770 [D loss: 0.972273, acc.: 45.00%] [G loss: 2.191898]\n",
      "771 [D loss: 1.291458, acc.: 45.00%] [G loss: 2.225616]\n",
      "772 [D loss: 1.038610, acc.: 55.00%] [G loss: 0.940720]\n",
      "773 [D loss: 1.409553, acc.: 55.00%] [G loss: 2.114885]\n",
      "774 [D loss: 1.141573, acc.: 50.00%] [G loss: 1.711516]\n",
      "775 [D loss: 1.215821, acc.: 45.00%] [G loss: 2.309259]\n",
      "776 [D loss: 1.521688, acc.: 35.00%] [G loss: 1.238896]\n",
      "777 [D loss: 0.941558, acc.: 55.00%] [G loss: 2.117104]\n",
      "778 [D loss: 1.043367, acc.: 50.00%] [G loss: 1.731167]\n",
      "779 [D loss: 0.736116, acc.: 70.00%] [G loss: 1.689472]\n",
      "780 [D loss: 1.340841, acc.: 40.00%] [G loss: 1.613733]\n",
      "781 [D loss: 0.825223, acc.: 55.00%] [G loss: 2.200386]\n",
      "782 [D loss: 1.331981, acc.: 50.00%] [G loss: 1.347852]\n",
      "783 [D loss: 1.075517, acc.: 45.00%] [G loss: 2.572382]\n",
      "784 [D loss: 0.629333, acc.: 70.00%] [G loss: 1.928599]\n",
      "785 [D loss: 0.972317, acc.: 50.00%] [G loss: 1.919249]\n",
      "786 [D loss: 1.013056, acc.: 50.00%] [G loss: 2.070931]\n",
      "787 [D loss: 1.268736, acc.: 35.00%] [G loss: 1.347807]\n",
      "788 [D loss: 1.300352, acc.: 35.00%] [G loss: 1.414354]\n",
      "789 [D loss: 1.124486, acc.: 40.00%] [G loss: 2.805793]\n",
      "790 [D loss: 1.376374, acc.: 35.00%] [G loss: 1.713674]\n",
      "791 [D loss: 0.703815, acc.: 65.00%] [G loss: 1.876237]\n",
      "792 [D loss: 0.925133, acc.: 60.00%] [G loss: 1.831973]\n",
      "793 [D loss: 0.773920, acc.: 70.00%] [G loss: 2.366259]\n",
      "794 [D loss: 1.422545, acc.: 45.00%] [G loss: 1.197788]\n",
      "795 [D loss: 1.091567, acc.: 55.00%] [G loss: 1.587656]\n",
      "796 [D loss: 1.073588, acc.: 50.00%] [G loss: 1.904412]\n",
      "797 [D loss: 1.220238, acc.: 35.00%] [G loss: 0.949475]\n",
      "798 [D loss: 1.287858, acc.: 35.00%] [G loss: 2.011267]\n",
      "799 [D loss: 0.700212, acc.: 60.00%] [G loss: 1.458275]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 [D loss: 0.492149, acc.: 70.00%] [G loss: 1.989642]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801 [D loss: 1.573298, acc.: 25.00%] [G loss: 1.356492]\n",
      "802 [D loss: 0.825881, acc.: 70.00%] [G loss: 2.049529]\n",
      "803 [D loss: 1.205472, acc.: 40.00%] [G loss: 1.200005]\n",
      "804 [D loss: 0.869038, acc.: 45.00%] [G loss: 2.167742]\n",
      "805 [D loss: 0.712557, acc.: 80.00%] [G loss: 1.380653]\n",
      "806 [D loss: 1.813954, acc.: 40.00%] [G loss: 2.835650]\n",
      "807 [D loss: 0.914047, acc.: 50.00%] [G loss: 2.518289]\n",
      "808 [D loss: 1.802070, acc.: 30.00%] [G loss: 1.228798]\n",
      "809 [D loss: 1.485225, acc.: 40.00%] [G loss: 1.963545]\n",
      "810 [D loss: 1.358232, acc.: 45.00%] [G loss: 2.761845]\n",
      "811 [D loss: 1.099361, acc.: 50.00%] [G loss: 4.013719]\n",
      "812 [D loss: 1.344974, acc.: 60.00%] [G loss: 2.590979]\n",
      "813 [D loss: 1.745996, acc.: 35.00%] [G loss: 1.264514]\n",
      "814 [D loss: 1.034447, acc.: 60.00%] [G loss: 2.116181]\n",
      "815 [D loss: 0.760544, acc.: 65.00%] [G loss: 2.446417]\n",
      "816 [D loss: 1.017053, acc.: 45.00%] [G loss: 1.722254]\n",
      "817 [D loss: 0.610563, acc.: 75.00%] [G loss: 3.395362]\n",
      "818 [D loss: 1.527386, acc.: 30.00%] [G loss: 1.585706]\n",
      "819 [D loss: 1.002498, acc.: 50.00%] [G loss: 2.225598]\n",
      "820 [D loss: 0.663920, acc.: 75.00%] [G loss: 1.819220]\n",
      "821 [D loss: 0.457666, acc.: 70.00%] [G loss: 1.751541]\n",
      "822 [D loss: 0.807520, acc.: 65.00%] [G loss: 1.606190]\n",
      "823 [D loss: 0.674319, acc.: 60.00%] [G loss: 2.301641]\n",
      "824 [D loss: 0.568761, acc.: 60.00%] [G loss: 1.217219]\n",
      "825 [D loss: 0.495831, acc.: 65.00%] [G loss: 1.731127]\n",
      "826 [D loss: 1.329279, acc.: 35.00%] [G loss: 3.011584]\n",
      "827 [D loss: 1.784050, acc.: 55.00%] [G loss: 1.604695]\n",
      "828 [D loss: 1.109965, acc.: 50.00%] [G loss: 2.094617]\n",
      "829 [D loss: 1.435757, acc.: 45.00%] [G loss: 1.826669]\n",
      "830 [D loss: 0.384060, acc.: 75.00%] [G loss: 0.479638]\n",
      "831 [D loss: 0.617200, acc.: 65.00%] [G loss: 1.673032]\n",
      "832 [D loss: 0.852468, acc.: 70.00%] [G loss: 4.012696]\n",
      "833 [D loss: 1.152183, acc.: 40.00%] [G loss: 1.709903]\n",
      "834 [D loss: 1.498932, acc.: 30.00%] [G loss: 2.053276]\n",
      "835 [D loss: 1.346991, acc.: 25.00%] [G loss: 2.063447]\n",
      "836 [D loss: 0.612232, acc.: 65.00%] [G loss: 1.869739]\n",
      "837 [D loss: 1.185887, acc.: 50.00%] [G loss: 0.409540]\n",
      "838 [D loss: 0.476718, acc.: 80.00%] [G loss: 0.937726]\n",
      "839 [D loss: 0.559351, acc.: 70.00%] [G loss: 0.671557]\n",
      "840 [D loss: 0.790016, acc.: 85.00%] [G loss: 0.295295]\n",
      "841 [D loss: 1.202959, acc.: 65.00%] [G loss: 2.786634]\n",
      "842 [D loss: 1.627492, acc.: 55.00%] [G loss: 1.592030]\n",
      "843 [D loss: 0.896313, acc.: 55.00%] [G loss: 2.399633]\n",
      "844 [D loss: 0.556953, acc.: 70.00%] [G loss: 3.256971]\n",
      "845 [D loss: 1.567737, acc.: 50.00%] [G loss: 2.463298]\n",
      "846 [D loss: 1.265303, acc.: 50.00%] [G loss: 0.290924]\n",
      "847 [D loss: 0.891407, acc.: 55.00%] [G loss: 2.277511]\n",
      "848 [D loss: 0.612368, acc.: 60.00%] [G loss: 2.767867]\n",
      "849 [D loss: 1.478127, acc.: 45.00%] [G loss: 2.972053]\n",
      "850 [D loss: 0.552859, acc.: 80.00%] [G loss: 1.649737]\n",
      "851 [D loss: 0.824299, acc.: 75.00%] [G loss: 1.063138]\n",
      "852 [D loss: 1.102430, acc.: 30.00%] [G loss: 3.222741]\n",
      "853 [D loss: 0.747849, acc.: 65.00%] [G loss: 2.854887]\n",
      "854 [D loss: 1.220122, acc.: 30.00%] [G loss: 2.988774]\n",
      "855 [D loss: 1.271334, acc.: 50.00%] [G loss: 3.132123]\n",
      "856 [D loss: 0.954444, acc.: 50.00%] [G loss: 2.935755]\n",
      "857 [D loss: 0.835777, acc.: 55.00%] [G loss: 1.508720]\n",
      "858 [D loss: 1.310901, acc.: 50.00%] [G loss: 3.009486]\n",
      "859 [D loss: 0.347281, acc.: 85.00%] [G loss: 3.526987]\n",
      "860 [D loss: 1.084213, acc.: 60.00%] [G loss: 1.964380]\n",
      "861 [D loss: 1.724259, acc.: 35.00%] [G loss: 2.224671]\n",
      "862 [D loss: 0.708702, acc.: 60.00%] [G loss: 3.330537]\n",
      "863 [D loss: 1.305560, acc.: 50.00%] [G loss: 0.719334]\n",
      "864 [D loss: 0.672748, acc.: 60.00%] [G loss: 1.047061]\n",
      "865 [D loss: 1.095570, acc.: 45.00%] [G loss: 0.928837]\n",
      "866 [D loss: 1.040528, acc.: 55.00%] [G loss: 2.134134]\n",
      "867 [D loss: 0.645263, acc.: 80.00%] [G loss: 1.229691]\n",
      "868 [D loss: 0.922854, acc.: 65.00%] [G loss: 2.008227]\n",
      "869 [D loss: 0.315412, acc.: 85.00%] [G loss: 3.014426]\n",
      "870 [D loss: 2.778671, acc.: 20.00%] [G loss: 3.652508]\n",
      "871 [D loss: 1.590973, acc.: 30.00%] [G loss: 3.011115]\n",
      "872 [D loss: 1.154835, acc.: 45.00%] [G loss: 1.218896]\n",
      "873 [D loss: 0.943300, acc.: 40.00%] [G loss: 1.247848]\n",
      "874 [D loss: 0.898706, acc.: 70.00%] [G loss: 1.063849]\n",
      "875 [D loss: 0.896236, acc.: 55.00%] [G loss: 4.054654]\n",
      "876 [D loss: 1.230890, acc.: 45.00%] [G loss: 1.756674]\n",
      "877 [D loss: 0.569360, acc.: 85.00%] [G loss: 1.614973]\n",
      "878 [D loss: 1.233109, acc.: 45.00%] [G loss: 2.105901]\n",
      "879 [D loss: 1.273005, acc.: 45.00%] [G loss: 1.745231]\n",
      "880 [D loss: 0.503505, acc.: 75.00%] [G loss: 1.410342]\n",
      "881 [D loss: 1.135916, acc.: 55.00%] [G loss: 0.894202]\n",
      "882 [D loss: 1.088529, acc.: 55.00%] [G loss: 3.152706]\n",
      "883 [D loss: 1.332800, acc.: 30.00%] [G loss: 2.128816]\n",
      "884 [D loss: 1.503815, acc.: 30.00%] [G loss: 1.131642]\n",
      "885 [D loss: 0.978387, acc.: 80.00%] [G loss: 2.048014]\n",
      "886 [D loss: 0.436543, acc.: 80.00%] [G loss: 1.445211]\n",
      "887 [D loss: 1.123608, acc.: 55.00%] [G loss: 1.577401]\n",
      "888 [D loss: 1.114364, acc.: 55.00%] [G loss: 3.269202]\n",
      "889 [D loss: 0.857735, acc.: 55.00%] [G loss: 1.282840]\n",
      "890 [D loss: 1.283048, acc.: 45.00%] [G loss: 2.494195]\n",
      "891 [D loss: 0.695984, acc.: 65.00%] [G loss: 1.417781]\n",
      "892 [D loss: 0.894561, acc.: 55.00%] [G loss: 2.040065]\n",
      "893 [D loss: 1.386519, acc.: 30.00%] [G loss: 2.288570]\n",
      "894 [D loss: 0.794755, acc.: 65.00%] [G loss: 3.973958]\n",
      "895 [D loss: 1.370289, acc.: 45.00%] [G loss: 1.183047]\n",
      "896 [D loss: 1.295565, acc.: 50.00%] [G loss: 2.342133]\n",
      "897 [D loss: 1.347532, acc.: 50.00%] [G loss: 1.703318]\n",
      "898 [D loss: 1.113949, acc.: 45.00%] [G loss: 3.395266]\n",
      "899 [D loss: 1.308842, acc.: 50.00%] [G loss: 2.682808]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900 [D loss: 1.563580, acc.: 35.00%] [G loss: 2.058248]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "901 [D loss: 1.011087, acc.: 45.00%] [G loss: 1.915667]\n",
      "902 [D loss: 0.686059, acc.: 50.00%] [G loss: 1.458012]\n",
      "903 [D loss: 1.320444, acc.: 55.00%] [G loss: 2.197258]\n",
      "904 [D loss: 0.991912, acc.: 55.00%] [G loss: 3.732198]\n",
      "905 [D loss: 1.981916, acc.: 10.00%] [G loss: 1.815904]\n",
      "906 [D loss: 1.438556, acc.: 40.00%] [G loss: 1.581141]\n",
      "907 [D loss: 1.219663, acc.: 50.00%] [G loss: 1.993969]\n",
      "908 [D loss: 1.351426, acc.: 35.00%] [G loss: 2.793697]\n",
      "909 [D loss: 0.983034, acc.: 65.00%] [G loss: 0.934728]\n",
      "910 [D loss: 1.489400, acc.: 40.00%] [G loss: 1.767362]\n",
      "911 [D loss: 0.946893, acc.: 50.00%] [G loss: 1.798622]\n",
      "912 [D loss: 0.642642, acc.: 70.00%] [G loss: 2.094504]\n",
      "913 [D loss: 1.252572, acc.: 45.00%] [G loss: 1.866804]\n",
      "914 [D loss: 0.928455, acc.: 45.00%] [G loss: 2.710680]\n",
      "915 [D loss: 0.745554, acc.: 70.00%] [G loss: 2.744526]\n",
      "916 [D loss: 1.210119, acc.: 35.00%] [G loss: 1.344050]\n",
      "917 [D loss: 1.251310, acc.: 40.00%] [G loss: 1.919237]\n",
      "918 [D loss: 0.846700, acc.: 60.00%] [G loss: 2.457897]\n",
      "919 [D loss: 0.992173, acc.: 55.00%] [G loss: 1.446250]\n",
      "920 [D loss: 0.469432, acc.: 80.00%] [G loss: 0.783794]\n",
      "921 [D loss: 0.882313, acc.: 65.00%] [G loss: 3.278897]\n",
      "922 [D loss: 1.056848, acc.: 50.00%] [G loss: 2.897984]\n",
      "923 [D loss: 0.922870, acc.: 55.00%] [G loss: 1.763037]\n",
      "924 [D loss: 0.914513, acc.: 65.00%] [G loss: 2.662361]\n",
      "925 [D loss: 0.895687, acc.: 65.00%] [G loss: 2.169470]\n",
      "926 [D loss: 1.320704, acc.: 45.00%] [G loss: 2.738962]\n",
      "927 [D loss: 1.030702, acc.: 60.00%] [G loss: 3.195647]\n",
      "928 [D loss: 1.293077, acc.: 45.00%] [G loss: 3.003900]\n",
      "929 [D loss: 1.183313, acc.: 25.00%] [G loss: 2.196992]\n",
      "930 [D loss: 1.004849, acc.: 50.00%] [G loss: 2.198868]\n",
      "931 [D loss: 0.850353, acc.: 60.00%] [G loss: 1.910979]\n",
      "932 [D loss: 0.947232, acc.: 35.00%] [G loss: 3.130852]\n",
      "933 [D loss: 0.694448, acc.: 75.00%] [G loss: 3.595758]\n",
      "934 [D loss: 1.505871, acc.: 35.00%] [G loss: 0.924872]\n",
      "935 [D loss: 0.816445, acc.: 60.00%] [G loss: 2.408779]\n",
      "936 [D loss: 0.763611, acc.: 55.00%] [G loss: 3.533635]\n",
      "937 [D loss: 1.188855, acc.: 55.00%] [G loss: 2.901642]\n",
      "938 [D loss: 1.616757, acc.: 30.00%] [G loss: 1.815074]\n",
      "939 [D loss: 0.762980, acc.: 55.00%] [G loss: 3.446021]\n",
      "940 [D loss: 1.746881, acc.: 15.00%] [G loss: 1.725643]\n",
      "941 [D loss: 0.981430, acc.: 55.00%] [G loss: 3.457039]\n",
      "942 [D loss: 1.473047, acc.: 30.00%] [G loss: 2.215305]\n",
      "943 [D loss: 0.809346, acc.: 70.00%] [G loss: 2.219225]\n",
      "944 [D loss: 0.821509, acc.: 75.00%] [G loss: 1.402550]\n",
      "945 [D loss: 0.882915, acc.: 60.00%] [G loss: 1.701288]\n",
      "946 [D loss: 0.776034, acc.: 70.00%] [G loss: 1.854867]\n",
      "947 [D loss: 0.844960, acc.: 65.00%] [G loss: 3.439891]\n",
      "948 [D loss: 1.212865, acc.: 50.00%] [G loss: 1.741745]\n",
      "949 [D loss: 0.623122, acc.: 70.00%] [G loss: 1.950271]\n",
      "950 [D loss: 0.855941, acc.: 50.00%] [G loss: 2.646441]\n",
      "951 [D loss: 0.424761, acc.: 80.00%] [G loss: 2.138114]\n",
      "952 [D loss: 1.609781, acc.: 45.00%] [G loss: 1.603764]\n",
      "953 [D loss: 0.984036, acc.: 65.00%] [G loss: 2.657701]\n",
      "954 [D loss: 1.762791, acc.: 15.00%] [G loss: 2.022080]\n",
      "955 [D loss: 0.976447, acc.: 60.00%] [G loss: 1.915527]\n",
      "956 [D loss: 1.841128, acc.: 20.00%] [G loss: 2.192840]\n",
      "957 [D loss: 0.658759, acc.: 65.00%] [G loss: 1.719654]\n",
      "958 [D loss: 1.379921, acc.: 35.00%] [G loss: 2.365179]\n",
      "959 [D loss: 0.657511, acc.: 55.00%] [G loss: 2.180605]\n",
      "960 [D loss: 0.991534, acc.: 55.00%] [G loss: 1.869337]\n",
      "961 [D loss: 1.668749, acc.: 35.00%] [G loss: 1.468449]\n",
      "962 [D loss: 0.892779, acc.: 45.00%] [G loss: 1.984943]\n",
      "963 [D loss: 1.735817, acc.: 30.00%] [G loss: 2.222424]\n",
      "964 [D loss: 0.718321, acc.: 65.00%] [G loss: 3.250555]\n",
      "965 [D loss: 0.925953, acc.: 45.00%] [G loss: 1.684114]\n",
      "966 [D loss: 0.703925, acc.: 60.00%] [G loss: 3.079670]\n",
      "967 [D loss: 0.718344, acc.: 70.00%] [G loss: 1.821699]\n",
      "968 [D loss: 1.103091, acc.: 50.00%] [G loss: 1.777983]\n",
      "969 [D loss: 0.597206, acc.: 60.00%] [G loss: 1.957509]\n",
      "970 [D loss: 0.999421, acc.: 50.00%] [G loss: 1.584991]\n",
      "971 [D loss: 0.682775, acc.: 65.00%] [G loss: 2.521493]\n",
      "972 [D loss: 1.022922, acc.: 50.00%] [G loss: 1.349211]\n",
      "973 [D loss: 0.972528, acc.: 55.00%] [G loss: 2.999665]\n",
      "974 [D loss: 1.116342, acc.: 30.00%] [G loss: 2.830997]\n",
      "975 [D loss: 1.320129, acc.: 25.00%] [G loss: 2.524598]\n",
      "976 [D loss: 0.988256, acc.: 50.00%] [G loss: 2.391428]\n",
      "977 [D loss: 0.537022, acc.: 80.00%] [G loss: 2.547388]\n",
      "978 [D loss: 1.336340, acc.: 40.00%] [G loss: 0.787510]\n",
      "979 [D loss: 1.100795, acc.: 60.00%] [G loss: 3.429363]\n",
      "980 [D loss: 0.754761, acc.: 75.00%] [G loss: 2.692789]\n",
      "981 [D loss: 1.504132, acc.: 30.00%] [G loss: 1.086562]\n",
      "982 [D loss: 0.976833, acc.: 60.00%] [G loss: 2.214007]\n",
      "983 [D loss: 0.480319, acc.: 80.00%] [G loss: 2.639872]\n",
      "984 [D loss: 1.498338, acc.: 45.00%] [G loss: 1.308337]\n",
      "985 [D loss: 1.818043, acc.: 30.00%] [G loss: 2.319176]\n",
      "986 [D loss: 0.666147, acc.: 60.00%] [G loss: 1.581143]\n",
      "987 [D loss: 0.272709, acc.: 90.00%] [G loss: 1.549937]\n",
      "988 [D loss: 1.108311, acc.: 40.00%] [G loss: 1.567534]\n",
      "989 [D loss: 0.656457, acc.: 75.00%] [G loss: 2.969186]\n",
      "990 [D loss: 1.217916, acc.: 40.00%] [G loss: 1.590720]\n",
      "991 [D loss: 1.309700, acc.: 40.00%] [G loss: 1.726926]\n",
      "992 [D loss: 0.474080, acc.: 75.00%] [G loss: 2.928975]\n",
      "993 [D loss: 1.121200, acc.: 45.00%] [G loss: 1.852041]\n",
      "994 [D loss: 1.920944, acc.: 30.00%] [G loss: 2.589409]\n",
      "995 [D loss: 0.603790, acc.: 65.00%] [G loss: 2.256316]\n",
      "996 [D loss: 0.667892, acc.: 65.00%] [G loss: 1.878379]\n",
      "997 [D loss: 1.019960, acc.: 50.00%] [G loss: 1.562054]\n",
      "998 [D loss: 0.900909, acc.: 55.00%] [G loss: 1.685479]\n",
      "999 [D loss: 1.551365, acc.: 40.00%] [G loss: 1.433373]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 [D loss: 0.889749, acc.: 55.00%] [G loss: 0.716815]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001 [D loss: 0.880612, acc.: 60.00%] [G loss: 1.260074]\n",
      "1002 [D loss: 0.567708, acc.: 65.00%] [G loss: 1.734889]\n",
      "1003 [D loss: 1.357617, acc.: 45.00%] [G loss: 1.515663]\n",
      "1004 [D loss: 0.899822, acc.: 45.00%] [G loss: 1.521122]\n",
      "1005 [D loss: 0.922614, acc.: 55.00%] [G loss: 1.451353]\n",
      "1006 [D loss: 1.195934, acc.: 45.00%] [G loss: 1.836034]\n",
      "1007 [D loss: 0.910982, acc.: 60.00%] [G loss: 1.569072]\n",
      "1008 [D loss: 1.142583, acc.: 55.00%] [G loss: 2.185969]\n",
      "1009 [D loss: 0.896961, acc.: 65.00%] [G loss: 2.902854]\n",
      "1010 [D loss: 0.681356, acc.: 75.00%] [G loss: 2.201629]\n",
      "1011 [D loss: 0.825907, acc.: 55.00%] [G loss: 2.799598]\n",
      "1012 [D loss: 1.088745, acc.: 45.00%] [G loss: 0.940833]\n",
      "1013 [D loss: 1.010046, acc.: 50.00%] [G loss: 1.842981]\n",
      "1014 [D loss: 0.501712, acc.: 75.00%] [G loss: 1.399047]\n",
      "1015 [D loss: 0.761987, acc.: 70.00%] [G loss: 3.806377]\n"
     ]
    }
   ],
   "source": [
    "g_loss, d_loss = gan.train(epochs=20001, batch_size=10, save_interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(g_loss)\n",
    "plt.plot(d_loss)\n",
    "plt.title('GAN Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Generator', 'Discriminator'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
